<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Recipe on francojc ⟲</title>
    <link>https://francojc.github.io/categories/recipe/</link>
    <description>Recent content in Recipe on francojc ⟲</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Jerid Francom</copyright>
    <lastBuildDate>Fri, 15 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/categories/recipe/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Introduction to statistical thinking</title>
      <link>https://francojc.github.io/2017/09/15/introduction-to-statistical-thinking/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://francojc.github.io/2017/09/15/introduction-to-statistical-thinking/</guid>
      <description>&lt;!-- TODOs:

- standardize usage of italics and bold for terms
- check links
- ...

--&gt;
&lt;p&gt;Before we begin working on the specifics of our data project, it is important to have a clear understanding of some of the basic concepts that need to be in place to guide our work. In this post I will cover some of these topics including the importance of identifying a research question, how different statistical approaches relate to different types of research, and understanding data from a sampling and organizational standpoint. I will also provide some examples of linking research questions with variables in a toy dataset as we begin to discuss how to approach data analysis, primarily through visualization techniques.&lt;/p&gt;
&lt;div id=&#34;research-aims&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Research aims&lt;/h2&gt;
&lt;!-- TODO: pepper in examples of the types of questions and methods one might find --&gt;
&lt;p&gt;Before jumping into the code, every researcher must come to a project with a clear idea about the purpose of the analysis. This means doing your homework in order to understand what it is exactly that you want to achieve; that is, you need to identify a &lt;strong&gt;research question&lt;/strong&gt;. The first step is become versed in the previous literature on the topic. What has been written? What are the main findings? Secondly, it is important to become familiar with the standard methods for approaching the topic of interest. How has the topic been approached methodologically? What are the types, sources, and quality of data employed? What have been the statistical approaches employed? What particular statistical tests have been chosen? Getting an overview not only of the domain-specific findings in the literature but also the methodological choices will help you identify promising plan for carrying out your research.&lt;/p&gt;
&lt;!-- All other steps in an analysis will be guided by this question and hinge on the choices you make conceptually to carry out a data analysis plan.  --&gt;
&lt;!-- * Identify a research question --&gt;
&lt;!--   - research previous literature --&gt;
&lt;!--   - get to know the nature of the phenomenon --&gt;
&lt;/div&gt;
&lt;div id=&#34;choosing-a-statistical-approach&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Choosing a statistical approach&lt;/h2&gt;
&lt;p&gt;With a research question in hand and a sense of how similar studies have approached the topic methodologically, it’s time to make a more refined decision about how the data is to be analyzed. This decision will dictate all other methodological choices from data collection to interpreting results.&lt;/p&gt;
&lt;p&gt;There are three main statistical approaches:&lt;/p&gt;
&lt;!-- * Identify goals of your analysis --&gt;
&lt;div id=&#34;inference&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Inference&lt;/h3&gt;
&lt;!-- TODO: find a way to introduce the concept &#39;model&#39;. this could make it easier to speak about statistical approaches, here and later in the post --&gt;
&lt;!-- TODO: pepper in examples of each type of statistical approach to ground these concepts a bit --&gt;
&lt;p&gt;Also commonly known as hypothesis testing or confirmation, statistical inference aims to establish whether there is a reliable and generalizable relationship given patterns in the data. The approach makes the starting assumption that there is no relationship, or that the null hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;) is true. A relationship is only reliable, or &lt;em&gt;significant&lt;/em&gt;, if the chance that the null hypothesis is false is less than some predetermined threshold; in which case we accept the alternative hypothesis (&lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;). The standard threshold used in the Social Sciences, Linguistic included, is the famous p-value &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .05\)&lt;/span&gt;. Without digging into the deeper meaning of a p-value, in a nutshell a p-value is a confidence measure to suggest that the relationship you are investigating is robust and reliable given the data. In an inference approach all the data is used and is used &lt;em&gt;only&lt;/em&gt; once. This is not the case for the other two statistical approaches we will cover, Exploration and Prediction. For this reason it is vital to identify your statistical approach from the beginning. In the case of inference tests, failing to make a clear hypothesis often leads to p-hacking; a practice of running multiple tests and/or parameters on the same data (i.e. reusing the data) until evidence for the alternative hypothesis appears.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exploration&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exploration&lt;/h3&gt;
&lt;p&gt;One of two statistical learning approaches, this statistical method is used to uncover potential relationships in the data and gain new insight in an area where predictions and hypotheses cannot be clearly made. In statistical learning, exploration is a type of &lt;strong&gt;unsupervised learning&lt;/strong&gt;. Supervision here, and for Prediction, refers to the presence or absence of an outcome variable. By choosing exploration as our approach we make no assumptions (or hypotheses) about the relationships between any of the particular variables in the data. Rather we hope to investigate the extent to which we can induce meaningful patterns wherever they may lie. Findings from exploratory analyses can provide valuable insight for future study but they cannot be safely used to generalize to the larger population, which is why exploratory analyses are often known as hypothesis generating analyses (rather than hypothesis confirming). Given our generalizing power is curtailed, the data &lt;em&gt;can&lt;/em&gt; be reused multiple times trying out various tests. While it is not strictly required, data for exploratory analysis is often partitioned into two sets, training and validation, at roughly an 80%/20% split. The training set is used for refining statistical measures and the test set is used to evaluate the refined measures. Although the evaluation results still cannot be used to generalize, the insight can be taken as stronger evidence that there is a potential relationship, or set of relationships, worthy of further study.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;prediction&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Prediction&lt;/h3&gt;
&lt;p&gt;The other statistical learning approach, Prediction, aims to uncover relationships in our data as they pertain to a particular outcome variable. This approach is known as &lt;strong&gt;supervised learning&lt;/strong&gt;. Similar to Exploration in many ways, this approach also makes no assumptions about the potential relationships between variables in our data and the data can be used multiple times to refine our statistical tests in order to tease out the most effective method for our goals. Where an exploratory analysis aims to uncover meaningful patterns of any sort, prediction, however, is more focused in that the main aim is to ascertain the extent to which the variables in the data pattern, individually or together, in such a way to make reliable associations to a particular outcome variable in unseen data. To evaluate the robustness of a prediction model the data is partitioned into training and validation sets. Depending on the application and the amount of available data, a third ‘development’ set is sometimes created as a pseudo test set to facilitate the testing of multiple approaches before the final evaluation. The proportions vary, but it a good rule of thumb is to reserve 60% of the data for training, 20% for development, and 20% for validation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;understanding-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Understanding data&lt;/h2&gt;
&lt;p&gt;Knowing the statistical approach to take then frames the next conceptual steps: &lt;strong&gt;data sampling&lt;/strong&gt; and &lt;strong&gt;organization of data&lt;/strong&gt;. But what is data anyway? Abstractly it is some set of empirical observations about the world. There are innumerable types of observations, as you can imagine, which can be used to describe objects and events. Our scientific aim is to systematically attempt to relate these observations and deduce the nature of their relationships to gain a better understanding of how our world works.&lt;/p&gt;
&lt;p&gt;Language research aims to understand a subset of these observations, namely those that concern linguistic behavior. The psycholinguist may observe the reaction times in a lexical decision task, eye-gaze in a visual world paradigm, or electro-magnetic brain activation in an ERP study. A sociolinguist may conduct interviews with members of a community, solicit language attitude responses to a language attitude survey, or ethnographically record face-to-face encounters. A syntactician may solicit acceptability ratings, calculate the frequency of a syntactic structure in a corpus, or document the permutations of subject-verb-object order in the world’s languages. As language is a defining characteristic of our species, language-related observations feature many other disciplines as well such as Anthropology, History, Neurology, Mathematics, and Biology. Linguistic inquiry, then, is not isolated to linguistic form, but rather the connection between linguistic form and other non-linguistic objects and events in the world at large –wherever that may take us.&lt;/p&gt;
&lt;!-- * Emperical observations --&gt;
&lt;!--   - Data is empirical observations about the world --&gt;
&lt;!--   - Innumberable types of observations: linguistic and non-linguistic --&gt;
&lt;!--   - Examples (acceptability ratings, reaction times, words in a corpus, lengths of words, age, sex, occupation, (non)-native speaker, etc.) --&gt;
&lt;div id=&#34;sampling&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Sampling&lt;/h3&gt;
&lt;p&gt;One major limitation inherent to most data sampling, and a primary reason why statistics are so important to doing and interpreting science, is the fact that our vantage point to the observing the world is restricted. We can only work with the data at our disposal, a &lt;strong&gt;sample&lt;/strong&gt;, even when it is clear that there is a much larger existing world, or &lt;strong&gt;population&lt;/strong&gt;. Ideally we would have access to the entire population of interest, but in most cases this is either not physically possible to obtain (or even store) the data or it is conceptually impossible to ever observe the entire population. As an example, say we wanted to catalog all the words in the English language. From a logistics point of view, where would we start? Any given dictionary only catalogs a subset of the words in a language –many words that are used in English-speaking communities, especially those from spoken language, will not appear. A corpus may capture linguistic diversity that does not appear in a dictionary, but it too will fall short of our lofty goal. But for argumentation sake, let’s imagine we could somehow capture all the words. What happens to our population in a day, a week, or a month from now? It quickly becomes a sample because new words are created all the time and some words are lost. Our population of words in the English language, then, is a moving target.&lt;/p&gt;
&lt;p&gt;This transitory property of populations is well-known and methods for obtaining reliable, or externally valid, samples is an area of study in its own right. In short, we aim for a sample to be balanced and representative of the idealized population. &lt;em&gt;Representativeness&lt;/em&gt; is the extent to which a sample reflects the total diversity in the population. &lt;em&gt;Balance&lt;/em&gt; is concerned with modeling the proportions of that diversity. An ideal sample combines both.&lt;/p&gt;
&lt;p&gt;The first strategy most often applied to obtaining a valid sample is to increase &lt;em&gt;sample size&lt;/em&gt;. This is an intuitive technique whose logic appeals to the notion that more is better. More is better, clearly. But more data alone does not always ensure an externally valid sample. For example, say we want to know something about the frequencies of words in written Spanish. Our target population is, then, words written in Spanish. It occurs to us that we can access a lot of written Spanish online via &lt;a href=&#34;http://www.gutenberg.org/&#34;&gt;Project Gutenberg&lt;/a&gt;. We download works from many authors over a span of many years. After doing some calculations our sample contains around 100 million words. That’s a lot of words, and surely more indicative of the population than say 100 thousand words. But we have potentially overlooked something very important: all of the data in our sample comes from literature, specifically literature in the public domain. In other words, our sample is not random.&lt;/p&gt;
&lt;p&gt;A &lt;em&gt;random sample&lt;/em&gt; will help increase the potential diversity in any sample. In our sample this means drawing data from a number of written sources of Spanish at random. This strategy will increase our chances to capture written Spanish from other genres and registers. Now a 100 million word sample randomly selected from genres and registers of written Spanish is bound to be more representative of the population, but we run into another conceptual snag. Our sample is large and randomly selected from the population, but does it reflect the proportion each subgroup (genres and registers) contributes to the idealized population?&lt;/p&gt;
&lt;p&gt;There is no absolute way of knowing if the proportions of each subgroup are balanced, or even what all the subgroups may be for that matter, but in most cases we can make an educated guess on both these fronts that will allow us to increase the validity of our sample. For example, the literary genre ‘self-help’ intuitively constitutes a smaller portion of our target population than say ‘news’. Ideally we would want to reflect this understanding in our sample. Applying this logic is known as &lt;em&gt;stratified sampling&lt;/em&gt;. A large, stratified random sample is always at least as valid as an equally sized large random sample with the added benefit that we are safeguarded from large skews that a large random sample may potentially produce. Now it is important to keep in mind that stratified sampling has its limitations as well. The difficulties posed in obtaining a valid sample from the macro view (i.e. the total population is never observable) are present at the micro view as well (i.e. sub- and sub-substrata are equally illusive). Again, there are no absolutes in sampling. The key is to keep the aim of the research question clear during the sampling process and strive for sizable, randomly stratified samples to minimize sampling error to the extent that it is feasible –and then work from there.&lt;/p&gt;
&lt;p&gt;This lack of certainty in sampling may seem troublesome. Sampling uncertainty, however, does not mean we cannot gain insight into the essence of the objects and events in the world we aim to understand. It just means we need to be aware of any given sample’s limitations, document these limitations, and always approach statistical findings based on this data with caution; suspending generalizations of the absolute nature. This is why science, contrary to popular belief, does not ‘prove’ anything. Rather science aims to collect evidence for or against a hypotheses. Since the data is always changing there are no absolute conclusions. As the evidence grows, so does the case for a particular view of how the world works. It is this systematic approach which makes science so powerful.&lt;/p&gt;
&lt;!-- * Populations and samples --&gt;
&lt;!--   - Ideally we would have access to the entire record of those observation that are of potential interest to us in our analysis --&gt;
&lt;!--   - Reality is we, more often than not, cannot feasibly acquire the observations of an entire population. --&gt;
&lt;!--   - The best we can do is shoot for a sample of that population which aims to model the population as appropriately possible given the particular research question to be addressed --&gt;
&lt;!--   - In the end we will always strive for a balanced and representative sample. A balanced sample contains the predicted major features indicative of the population. A representative sample contains these features in a way that reflect the proportion of these features.  --&gt;
&lt;!--   - Attaining the most ideal sample given the potential limitations is key to gaining robust and generalizable insight into the nature of the phenomenon we are investigating.  --&gt;
&lt;/div&gt;
&lt;div id=&#34;organization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Organization&lt;/h3&gt;
&lt;p&gt;Identifying and capturing a data sample moves us one step closer to performing our data analysis but the format of the raw or original data is often not in a format conducive for visualization nor statistical tests. The hypothetical written Spanish data we identified to sample in the previous section would most likely take the form of documents of running text with potentially some meta-data about the text (author, title of the work, date published, genre, etc.) in the header of the file and/or the name of each file.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Title: Cuando los robots tomen el mando y hagan la guerra
Date: 3 AGO 2015 - 00:00 CEST
Genre: News
Source: El País
Tags: Científicos, Isaac Asimov, Robótica, Gente, Tecnología, Informática, Ciencia, Sociedad, Industria

La primera reflexión abarcadora sobre la coexistencia entre los robots y los humanos no fue obra de un científico de la computación ni de un filósofo ético, sino de un novelista. Isaac Asimov formuló las tres “leyes de la robótica” que deberían incorporarse en la programación de cualquier autómata lo bastante avanzado como para suponer un peligro: “No dañar a los humanos, obedecerles salvo conflicto con lo anterior y autoprotegerse salvo conflicto con todo lo anterior”. Las tres leyes de Asimov configuran una propuesta sólida y autoconsistente, y cuentan con apoyo entre la comunidad de la inteligencia artificial, que reconoce, por ejemplo, que cualquier sistema autónomo funcional debe ser capaz de autoprotegerse.
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As raw data this format is fine, but to gain insight from this data, we will need to explicitly organize the attributes of our data that are key to our analysis. Our data should be in tabular, or ‘tidy’ format where each row is an observation, or &lt;strong&gt;case&lt;/strong&gt; and each column, or &lt;strong&gt;variable&lt;/strong&gt; is a list of attributes of the observation. Each cell, then, is a particular attribute of a particular observation, or &lt;strong&gt;data point&lt;/strong&gt;. Say our objective is to perform an exploratory analysis to evaluate the potential similarities and differences in word frequencies between genres. For this particular analysis we will want to extract and organize the title of each document (&lt;code&gt;doc_id&lt;/code&gt;), the genre it is from (&lt;code&gt;genre&lt;/code&gt;), and each word (&lt;code&gt;word&lt;/code&gt;) as a single, row, or observation, in our tidy dataset.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:spanish-works&#34;&gt;Table 1: &lt;/span&gt;Tidy dataset&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;doc_id&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;genre&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;word&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;es&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;son&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;peligro&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;guerra&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;lo&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;por&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;han&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;á&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;considerado&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;de&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;celoso&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;guide&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;esperan&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;teme&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;el&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;This tidy organization may seem somewhat redundant; a single value for &lt;code&gt;doc_id&lt;/code&gt; is repeated for each value of &lt;code&gt;word&lt;/code&gt; and a single value of &lt;code&gt;genre&lt;/code&gt; is repeated for each value of &lt;code&gt;doc_id&lt;/code&gt;. However tidy data, although visually redundant, is an explicit description of the relationship between our variables. Each row corresponds to all of the necessary attributes to describe a particular observation. In this data, the occurrence of a word is associated with the file it appears in and the genre that file is associated with.&lt;/p&gt;
&lt;!-- TODO: consider the format that is required for doing a cluster analysis. Is my discussion leading in that direction, or is it complicated by potentially needing to create a term-document matrix? Look at the `tidytext` package vignette. Might need to change the discussion to focus on an inference analysis: assume a hypothesis that a specific register is more lexically diverse than another. Include genre as a factor? --&gt;
&lt;p&gt;Our objective in this toy example is to explore the relationship between word frequencies and genres, yet at this point there is no explicit variable for the frequencies of words. The information we need, however, is in the data and since we have an organized, tidy dataset, calculating &lt;code&gt;word_freq&lt;/code&gt; is a matter of tabulating the occurrences of each word. This can be done easily with R, as we will see in detail in future posts, but for our discussion on data organization let’s skip the details and jump to the new dataset with a column for &lt;code&gt;word_freq&lt;/code&gt;.&lt;/p&gt;
&lt;!-- example tabular data: doc_id, genre, word. Adding the word_freq column --&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:spanish-works-freq&#34;&gt;Table 2: &lt;/span&gt;Tidy dataset with &lt;code&gt;word_freq&lt;/code&gt; variable.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;doc_id&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;genre&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;word&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;word_freq&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;de&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;747&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;la&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;559&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;el&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;376&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;en&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;309&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cosmografía&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Astronomy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;que&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;306&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;de&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;33&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;la&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;y&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;20&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;los&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cuando los robots tomen el mando y hagan la guerra&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;News&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;que&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;to&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;314&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;de&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;217&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;a&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;206&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;que&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;175&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Heath’s Modern Language Series: El trovador&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Opera&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;_m&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;172&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Other measures and/or attributes can be added as necessary to this tabular format and in some cases we may convert our tidy tabular dataset to other data formats that may be required for some particular statistic approaches but at all times the relationship between the variables should be maintained in line with our research purpose. We will touch on examples of other types of data formats when we dive into particular statistical approaches that require them later in the series.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;informational-value&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Informational value&lt;/h3&gt;
&lt;p&gt;Let’s turn now to the informational nature of our variables as it will set up how we implement our data analysis. Taking our variable &lt;code&gt;word_freq&lt;/code&gt; as an example, it is important to point out there are many ways to define ‘frequency’. Some frequency measures are more appropriate than others given the statistical approach we intend to apply to our data. Our current dataset contains raw frequency scores, that is the frequency is measured in observed counts for each word in each file of our data. We could, for example, instead bin our frequency scores under the labels “high” and “low” frequency converting frequency from counts to labels. In this case we change the &lt;strong&gt;informational value&lt;/strong&gt; of &lt;code&gt;word_freq&lt;/code&gt;. Some variables in our dataset, on the other hand, cannot be converted. Take for example, &lt;code&gt;genre&lt;/code&gt;. The values for &lt;code&gt;genre&lt;/code&gt; label the genre of the file from which the word was observed. We could of course summarize the genres under meta-genres, but we maintain labeled data; the same informational value as before.&lt;/p&gt;
&lt;p&gt;Understanding the informational value of variables in key to organizing and preparing your data for analysis as it has implications for what insight we can gain from the data and what visualization techniques and statistical measures we can use to interrogate the data. There are four potential informational values for all data: nominal, ordinal, interval, and ratio.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Nominal variables&lt;/em&gt; contain attributes which are labels denoting the membership in a class in which there is no relationship between the labels. Examples of nominal data include part-of-speech labels, the sex of a participant, the genre of a text, etc.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Ordinal variables&lt;/em&gt; also contain labels of classes, but in contrast to nominal variables, there is a relationship between the classes, namely one in which there is a precedence relationship or rank. Our frequency conversion from scores to high- and low-frequency bins is a type of ordinal data –there is an explicit ordering of these two categories. Grouping participants in a study as “young”, “middle-aged”, and “old” would also be ordinal values; again, each value can be interpreted in relationship to the other values.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Interval variables&lt;/em&gt; are like ordinal variables in which there is an explicit precedence relationship, but in addition the values describe precise intervals between each value. So take our earlier operationalization of age as “young”, “middle-aged”, and “old”. As an ordinal variable no assumption is made that the differences in age between young and middle-aged are the same as between middle-aged and old –only that one class is ordered before or after another. If our criterion to code our values of age, however, were based regular intervals between age groups, not some non-regular assignment, then our values of age would be interval-valued.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Ratio variables&lt;/em&gt; have all the properties of interval variables but also include a non-arbitrary definition of zero. Frequency counts are ratio variables as it is clear that there is a potential value for 0 and any value greater can be interpreted in reference to this anchor. A word with a frequency of 100 is two times as large as a word with frequency 50. By the same token, a participant that is 20 years old is half the age of a 40 year old participant.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These informational types are often described in macro terms grouping nominal and ordinal variables as &lt;strong&gt;categorical variables&lt;/strong&gt; and interval and ratio variables as &lt;strong&gt;continous variables&lt;/strong&gt;. All continuous variables can be converted to categorical variables, but the reverse is not true. In most cases it is preferred to cast your data as continuous, if the nature of the variable permits it, as the recasting of continuous data to categorical data results in a loss of information –which will result in a loss of statistical power and may lead to results that obscure meaningful patterns in the data.&lt;/p&gt;
&lt;!-- The structure of raw, or original, data sampled varies  --&gt;
&lt;!-- * Informational value of variables --&gt;
&lt;!--   - In preparation for analysis, the research must be cognicent of the informational status of the variables of the data --&gt;
&lt;!--   - Variables are the observational features, attributes, and measures --&gt;
&lt;!--   - Ultimately visualizing and performing statistical operations on your data to analyze your data will depend on these variables and the information they contain. --&gt;
&lt;!--   - There are four informational types of variables: --&gt;
&lt;!--     * Nominal --&gt;
&lt;!--     * Ordinal --&gt;
&lt;!--     * Ratio --&gt;
&lt;!--     * Interval --&gt;
&lt;!--   - For convenience, we often talk about two major classes --&gt;
&lt;!--     * Categorical (nominal/ ordinal) --&gt;
&lt;!--     * Continuous (ratio/ interval) --&gt;
&lt;!--   - (Examples of real data sets) --&gt;
&lt;!-- * Operationalizing variables --&gt;
&lt;!--   - While some variables and their informational value are self-evident (such as sex, or age), some need to be interpreted and explicitly formulated --&gt;
&lt;!--   - Measurements --&gt;
&lt;!--     * Some variables contain information that needs to be calculated (frequencies, dispersion, etc.) or transformed (log, normalization (z-scores, etc.)) to be meaningful for analysis --&gt;
&lt;/div&gt;
&lt;div id=&#34;dependent-and-independent-variables&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dependent and independent variables&lt;/h3&gt;
&lt;p&gt;The last step before we move to visualization and statistical tests is to identify our &lt;strong&gt;dependent variable&lt;/strong&gt; and/ or &lt;strong&gt;independent variables&lt;/strong&gt;. A dependent variable is the outcome variable that is used in inference and prediction analyses that reflects the observations of the behavior we want to gain understanding about. The identification of a dependent variable should be guided by your research question; it is the measure of the phenomenon in question. An independent variable is a predictor variable, or a variable which we assume will be related to the values of the dependent variable in some systematic way. There is typically only one dependent variable in an analysis, but there can be multiple independent variables. In an exploratory analysis, however, all the variables are independent variables as this approach assumes no particular relationship between the variables; the goal in this approach, remember, is to uncover patterns that may suggest a relationship between particular set of variables.&lt;/p&gt;
&lt;!-- * Dependent and independent variables --&gt;
&lt;!--   - Another key distiction to be made with our variables concerns the linking of our variables with the research question and statistical approach we intend to use to explore this question and it&#39;s predictions.  --&gt;
&lt;!--   - A dependent variable is the variable that is considered the outcome measurement to be understood.  --&gt;
&lt;!--   - Independent variables are those variables that we aim to use to understand the nature and variability of the dependent variable --&gt;
&lt;!--   - In hypothesis testing or prediction a dependent variable must be identified (in prediction this variable is also called the class or outcome variable) --&gt;
&lt;!--   - For exploration, where the goal is to discover patterns, the dependent variable is unknown and is the feature that we aim to discover --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;data-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data analysis&lt;/h2&gt;
&lt;p&gt;The primary goal of a data analysis is to reduce the observed data to a human-interpretable summary that best approximates the nature of the phenomenon we are investigating. With well-sampled data in a tidy dataset in hand where observations and variables are explicitly related, identified for their informational value, and the dependent and/or independent variables are clear, we can now proceed to visualizing and applying the appropriate statistical tests to the data to come to some more concrete, actionable insight.&lt;/p&gt;
&lt;div id=&#34;visualization&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Visualization&lt;/h3&gt;
&lt;p&gt;Tt is always key to gain insight into the behavior of the data visually before jumping in to the statistical analysis. Using our research aim as our guide, we will choose the most appropriate visualization to use given the number and informational value of our target variables. To get a sense of how this looks, let’s work with an example dataset and pose different questions to the data with an eye towards seeing how various combinations of variables are visualized.&lt;/p&gt;
&lt;p&gt;The dataset we will use here is from the &lt;a href=&#34;http://talkbank.org/&#34;&gt;TalkBank repository&lt;/a&gt; which provides data from various language learning contexts.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The specific data we will use is the ‘narratives’ section of the &lt;a href=&#34;http://talkbank.org/access/SLABank/English/BELC.html&#34;&gt;BELC (Barcelona English Language Corpus)&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(Muñoz 2006)&lt;/span&gt;. It is a corpus of writing samples from second language learners of English at different ages. Participants were given the task of writing for 15 minutes on the topic of “Me: my past, present and future”. Data was collected for many (but not all) participants up to four times over the course of seven years. The entire dataset includes 123 observations from 54 participants. Below I’ve included the first 10 observations from the dataset which reflects some data cleaning I’ve done so we start with a tidy dataset.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:view-belc-dataset&#34;&gt;Table 3: &lt;/span&gt;BELC dataset for demonstration.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;participant_id&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;learner_group&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;tokens&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;01&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;120&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;01&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;03&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;03&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;04&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;04&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;73&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The variables &lt;code&gt;participant_id&lt;/code&gt;, &lt;code&gt;sex&lt;/code&gt;, and &lt;code&gt;age&lt;/code&gt; should be self-explanatory. &lt;code&gt;learner_group&lt;/code&gt; contains the values 1-4 which record the stage for each participant formally learning English. The number of words written in each sample is listed for each participant at each stage in the variable &lt;code&gt;tokens&lt;/code&gt;. We should also note the informational value of these variables. &lt;code&gt;participant_id&lt;/code&gt;, &lt;code&gt;sex&lt;/code&gt;, and &lt;code&gt;learner_group&lt;/code&gt; are categorical variables; both &lt;code&gt;participant_id&lt;/code&gt; and &lt;code&gt;sex&lt;/code&gt; are nominal and &lt;code&gt;learner_group&lt;/code&gt; is ordinal. &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt; are continuous variables; both of the ratio type as they are scaled in relation to a non-arbitrary value for zero.&lt;/p&gt;
&lt;p&gt;With general understanding of the data, let’s run through various data analysis scenarios and their corresponding visualizations grouping them by the information value of the dependent variable.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Categorical dependent variable&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;No independent variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Starting basic, let’s say we are interested in investigating the difference in the number of &lt;code&gt;males&lt;/code&gt; and &lt;code&gt;females&lt;/code&gt; in our study. This is not a particularly interesting question, but it allow us to illustrate a scenario in which we have a single dependent variable, &lt;code&gt;sex&lt;/code&gt;, which is categorical. When summarizing categorical data we produce counts of each of the levels of that variable. We can visualize this summary in one of two ways, textually and graphically. A text summary would look like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sex
female   male 
    67     56 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A graphic display does not necessarily facilitate a better understanding, in such a simple case, but let’s graphically visualize this scenario anyway. The type of plot we want to use is a ‘bar plot’, which simply plots the dependent variable on the x-axis and the counts on the y-axis.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-cat&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-cat-1.png&#34; alt=&#34;Bar plot of the categorical variable `sex`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Bar plot of the categorical variable &lt;code&gt;sex&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Inspecting these visualizations it is clear that there is a numeric difference between the number of writing samples in the data written by women. At this point, however, we only have a trend. To decide whether this is a reliable contrast is the purpose of our statistical tests, but we’ll leave the details of statistical testing for this scenario, and those that follow, for subsequent posts.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;One categorical independent variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A more common scenario is one in which we have a categorical dependent variable and a categorical independent variable. With our data we can investigate the relationship between &lt;code&gt;sex&lt;/code&gt; and the &lt;code&gt;learner_group&lt;/code&gt;. Are there more males than females in a particular learner group? In this case both variables are categorical and the dimensions are such that we can textually represent them and gain some insight.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;        learner_group
sex       1  2  3  4
  female 20 24 13 10
  male   15 23 13  5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s more difficult to see the pattern here than in the basic single dependent variable scenario for two reasons: 1) as the number of independent variables and/or the levels within an independent variable increase, our ability to interpret the results decreases. 2) the relationship between &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;learner_group&lt;/code&gt; does not take into account that there are more female samples than males, and therefore the raw counts here can be misleading.&lt;/p&gt;
&lt;p&gt;A graphic representation of this contrast will be a bit easier to interpret; although it is important to be aware that more variables and levels always leads to interpretability problems. The bar plot below reflects the raw counts from the cross-tabulation of the variables &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;learner_group&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-cat-ind-cat-graph&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-cat-ind-cat-graph-1.png&#34; alt=&#34;Bar plot of the variable `sex` and `learner_group`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Bar plot of the variable &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;learner_group&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Adjusting the bar plot to account for the proportions of males to females in each group provides a clearer picture of the relationship between &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;learner_group&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-cat-ind-cat-graph-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-cat-ind-cat-graph-2-1.png&#34; alt=&#34;Bar plot of the variable `sex` and `learner_group` proportionally scaled.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Bar plot of the variable &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;learner_group&lt;/code&gt; proportionally scaled.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From this visualization it appears that there are more females in the first and last learner groups.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Two categorical independent variables&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s look at a more complex case in which we have two categorical independent variables. Now the dataset, as is, does not have a third categorical variable for us to explore but we can recast the continuous &lt;code&gt;tokens&lt;/code&gt; variable as a categorical variable if we bin the scores into groups. I’ve binned &lt;code&gt;tokens&lt;/code&gt; into three score groups with equal ranges in a new variable called &lt;code&gt;token_bins&lt;/code&gt;.&lt;/p&gt;
&lt;table&gt;
&lt;caption&gt;&lt;span id=&#34;tab:token-bins&#34;&gt;Table 4: &lt;/span&gt;&lt;code&gt;belc&lt;/code&gt; dataset with categorical &lt;code&gt;token_bins&lt;/code&gt; variable added.&lt;/caption&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;participant_id&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;sex&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;learner_group&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;age&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;tokens&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;token_bins&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;01&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;120&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;01&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;43&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;02&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;female&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;26&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;03&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;16&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;03&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;28&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;04&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;32&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;low&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;04&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;male&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;12&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;73&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;mid&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Adding a second categorical independent variable ups the complexity of our analysis and as a result our visualization strategy will change. As text our data will include individual two-way cross-tabulations for each of the levels for the third variable. In this case it is often best to use the variable with the fewest levels as the third variable.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;, , sex = female

             token_bins
learner_group low mid high
            1  18   2    0
            2  18   6    0
            3   9   4    0
            4   7   2    1

, , sex = male

             token_bins
learner_group low mid high
            1  13   2    0
            2  15   7    1
            3   8   5    0
            4   2   3    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To graphically visualize three categorical variables we turn to a mosaic plot.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-cat-ind-cat-2-graph&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-cat-ind-cat-2-graph-1.png&#34; alt=&#34;Mosaic plot contrasting the categorical variables `sex`, `learner_group`, and `token_bins`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Mosaic plot contrasting the categorical variables &lt;code&gt;sex&lt;/code&gt;, &lt;code&gt;learner_group&lt;/code&gt;, and &lt;code&gt;token_bins&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From these visualizations we can see there is a general trend for the tokens from writing samples to increase in higher learner groups. There are some apparent divergent scores from this trend to be cautious of, however.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Continuous dependent variable&lt;/strong&gt;&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;No independent variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Working with a single continuous dependent variable means that the only practical way to summarize the data is graphically –as textual visualization will be very verbose and by and large uninterpretable. Plotting a single continuous variable often takes the form of a histogram which summarizes the frequency of the values of the dependent variable. So from our dataset, we may want to know what the distribution of &lt;code&gt;token&lt;/code&gt; scores looks like. That is, are they normally distributed (‘bell-shaped’), or skewed to the left or right (more values in the low or high range), or some other type of distribution (i.e. bi-modal, etc.)?&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-graph&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-graph-1.png&#34; alt=&#34;Histogram (with and without a density line) for the continuous variable `tokens`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Histogram (with and without a density line) for the continuous variable &lt;code&gt;tokens&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The plot on the left is a standard histogram and the plot on the right is the same histogram with a density line added to highlight the distribution. From these plots we see that token counts are slightly left skewed. The longer tail to the right for higher token scores shows some evidence of outliers –that is, scores that are uncharacteristic of the general data distribution. For many analyses plotting a histogram is a key first step to identifying they type of statistical test to use on the data as certain test have assumptions about how the data should be distributed for their results to be reliable. For example, a class of tests called &lt;em&gt;parametric&lt;/em&gt; assume that continuous data is normally distributed (&lt;em&gt;non-parametric&lt;/em&gt; tests do not make this assumption). Having plotted the data we can see that it is probably not normally distributed. All is not lost, however. There are methods for &lt;em&gt;transforming&lt;/em&gt; the data that can often times take mildly skewed data and coerce it into a normal distribution.&lt;/p&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;One categorical independent variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Another common data analysis scenario is one in which we have a continuous dependent variable and one categorical independent variable. Say we wanted to know the average number of &lt;code&gt;tokens&lt;/code&gt; used by men and by women. We would use the &lt;code&gt;tokens&lt;/code&gt; variable as our dependent variable and and &lt;code&gt;sex&lt;/code&gt; as the independent variable. We can visualize these means textually, as we are calculating the mean for each level of &lt;code&gt;sex&lt;/code&gt;,&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;  female     male 
57.14925 60.80357 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;or graphically with a box plot, in which we get a host of information about the distribution.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-ind-cat-graph&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-ind-cat-graph-1.png&#34; alt=&#34;Box plot summarizing the contrast between `sex` and `tokens`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: Box plot summarizing the contrast between &lt;code&gt;sex&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;If you take a look at the results in the box plot you will see that the medians (the &lt;strong&gt;bold horizontal lines&lt;/strong&gt;) are not that different. Note that the mean and the median measure different things. And the mean is more sensitive to outliers –and the plot shows that there are some outliers in the male and female data. When we statistically analyze the data these types of outliers contribute to unexplained variation, or ‘noise’ at it is often called. Noise has the effect of reducing our confidence that the differences between populations are real, and not likely due to chance. We see much more on this later in the series.&lt;/p&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;One continuous independent variable&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The behavior of two continuous variables, one dependent and the other independent is represented using a scatter plot. The value for each variable for each observation is plotted as a coordinate pair. From this mapping we evaluate the relationship, or correlation, between the variables. Sticking with &lt;code&gt;tokens&lt;/code&gt; as our measure, let’s explore the extent to which &lt;code&gt;age&lt;/code&gt; conditions the number of tokens used by a participant.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-ind-con-graph&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-ind-con-graph-1.png&#34; alt=&#34;Scatter plot visualizing the correlation between the continuous variables `age` and `tokens`.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: Scatter plot visualizing the correlation between the continuous variables &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From a visual inspection it appears that there is a slight effect for &lt;code&gt;age&lt;/code&gt; on &lt;code&gt;tokens&lt;/code&gt;, namely that the older the participant the more tokens they tend to use.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; It is often helpful, and/ or necessary to add a trend line to the plot to help see the relationship more clearly. Note that the ribbon (in grey) surrounding the trend line is the ‘standard error’, or SE. The SE is a confidence interval suggesting that the trend line could have been drawn within any part of this space. You will note that a larger ribbon width corresponds with more variability. This is clearly the case for the tokens used by participants at age 14.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-ind-con-graph-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-ind-con-graph-2-1.png&#34; alt=&#34;Scatter plot visualizing the correlation between the continuous variables `age` and `tokens` with a trend line.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: Scatter plot visualizing the correlation between the continuous variables &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt; with a trend line.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Another note on the trend line. The trend line drawn here is a non-linear, which is why you see the line is bendy. Often times when we are doing hypothesis testing we will be making the assumption that the relationship between two or more variables is linear, not non-linear. We can add a linear trend line to get a better understanding of the linear relationship between our variables.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-ind-con-graph-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-ind-con-graph-3-1.png&#34; alt=&#34;Scatter plot visualizing the correlation between the continuous variables `age` and `tokens` with a linear trend line.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 9: Scatter plot visualizing the correlation between the continuous variables &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt; with a linear trend line.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Interpreting the linear representation we see there is an apparent trend for increasing values for &lt;code&gt;tokens&lt;/code&gt; as &lt;code&gt;age&lt;/code&gt; increases.&lt;/p&gt;
&lt;p&gt;Say our aim was to understand the relationship between &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt; as a potential function of &lt;code&gt;sex&lt;/code&gt;. We can incorporate &lt;code&gt;age&lt;/code&gt; as a categorical variable. The result provides us a scatter plot with two trend lines, one for each level of &lt;code&gt;sex&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:dep-con-ind-con-graph-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-09-15-introduction-to-statistical-thinking_files/figure-html/dep-con-ind-con-graph-4-1.png&#34; alt=&#34;Scatter plot visualizing the correlation between the continuous variables `age` and `tokens` by `sex` with a linear trend line.&#34; width=&#34;80%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 10: Scatter plot visualizing the correlation between the continuous variables &lt;code&gt;age&lt;/code&gt; and &lt;code&gt;tokens&lt;/code&gt; by &lt;code&gt;sex&lt;/code&gt; with a linear trend line.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;From this visualization we see there is an apparent difference between males and females. Namely, males appear to increase their token production more than females of the same age. The SE ribbons here, however, are telling. Since they overlap we should be very cautious in interpreting the difference the trend line shows. Overlapping SE ribbons suggest the trend line could have been drawn in this space and therefore there is a likely probability that the visual difference will not result in a statistical difference. Again, this is another example of why visualization is such an integral first step in data analysis.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;statistical-tests&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Statistical tests&lt;/h3&gt;
&lt;p&gt;In the previous section various visualization strategies were illustrated through the lens of typical data analysis scenarios. To gain confidence that the trends in the data that we observe are reliable we submit the data to statistical tests. There are numerous tests available, too many to discuss at this point. But it is important to understand that much like our visualization choices, the test we choose depends on the number of variables we are investigating and the information values of these variables. However, particular statistical tests also potentially require a number of test specific assumptions (such as whether the data is normally distributed, for example). We will cover these on a case by case basis later on in the series.&lt;/p&gt;
&lt;!-- * Goal is to reduce the data into a summary of the data that best approximates the nature of the phenomenon that we are investigating.  --&gt;
&lt;!--   - To do this we start with visualization to gain an intuitive understanding of the distribution of the data and variables of interest. This exploratory process should be guided by your research question and statistical aims (hypothesis in hypothesis testing). It is fundamental to build up this graphic and mental picture of our data before moving to statistically evaluate the relationships of interest. --&gt;
&lt;!--   - (Examples) --&gt;
&lt;!--   - With an intuition of the data, awareness of the informational values of our variables, and having identified dependent and independent variables, we proceed to statistical analysis to develop a model that achieves these goals. Ultimately we want to know if the nature of the connections between our variables are reliable. That&#39;s what statistics will do for us. --&gt;
&lt;!--   - (Examples) --&gt;
&lt;!-- Keep these examples brief, as we will deal with data analysis head on later in the series.  --&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;round-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Round up&lt;/h2&gt;
&lt;p&gt;In this post we covered some foundational topics for any data analysis project. Guiding the entire process is a clear research question. From there we can proceed to acquire data that is relevant and reliable on the phenomenon we hope to understand better, choose a statistical approach which matches our analysis goals, and organize our data into a format conducive for achieving these goals. Only at this point can we confidently move to analyzing our data, first beginning with appropriate visualization techniques to get a feel for the trends and then moving to performing the relevant statistical tests to provide confidence that the trends captured in our visualizations are in fact reliable.&lt;/p&gt;
&lt;p&gt;There is still much left to discuss, in particular what statistical tests to apply to a given data analysis scenario and the assumptions behind statistical tests. We will address these topics later in the series when we have established a stronger and practical understanding of the preceding project steps and increase our proficiencey programming in R. The first step in this journey will be to learn about the specifics of acquiring data for language research; where to find it and how to obtain. We will also begin working directly with R code and introduce fundamental programming concepts of the language you will use throughout your project.&lt;/p&gt;
&lt;!-- OTHER APPROACHES TO THE TOPIC

GRIES, Statistics for Linguists with R
CHAPTER 1

* Design and logic of quantitative studies
  - Linguistics is an empirical science; thus understanding empirical methods and statistics is key to undertanding scientific and linguistic argumentation
  - Choosing a topic -consult the literature and get a feel for the area
* Reseach aims 
  - Hypotheses
  - Exploratory analysis
  - (Prediction -not covered but would logically fall here)
* Variables and measures
  - Operationalizing variables
  - Informational value (level of measurement)
  - Dependent and independent variables
    * Measure of dependent variable
    * Number of independent variables
* Data
  - Populations and samples (aiming for a balanced, representative sample)
  - Format for analysis (tidy, basically)


WICKHAM, R for Data Science
EXPLORE

* Data science workflow (overview)
* Data visualization (ggplot2, grammar of graphics fundamentals)
* Exploratory data analysis (EDA)
  - Variation
  - Covariation
  - Patterns and models (modelling concepts)

MODEL

* Hypothesis generating (exploration) vs. hypothesis confirmation (testing/ inference)
  - Observations may be used only once for inference, but multiple times for exploration
  - Modelling: creating a low-dimension summary of the dataset
  - Choosing a model (model selection)

JOHNSON, Quantitative Methods in Linguistics

Chapter 1:

* Goals of quantitative analyses
  - Data reduction
  - Inference (confirm a hypothesized relationship)
  - Exploration (discover relationships)
  - Explore processes (? not sure I like this; I would add Prediction (leverage/ harness relationships for predicting events) )
* Observations
  - What is an observation?
  - Informational values of observations (variables)
* Measures
  - Frequency distributions
  - Shapes of distributions
    * Uniform, skewed (right or left), bimodal, normal, J-shaped, U-shaped
  - Importance of the normal distribution
    * What is the normal distribution and why is it important?
      * Assumption for many statistical tests
    * How do we know if the data is normal?
    * Transforming data to fit the normal distribution
  - Measures of central tendency
    * Mean (arithmatic), median, and mode
  - Measure of dispersion
    * Variance
    * Standard deviation

Chapter 2:

* Sampling
  - What makes a good sample?
* Data
  - Observations
  - Good samples are critical to a sound analysis (your findings cannot be more reliable than your data!)
* Hypothesis testing
  - Central Limit Theorem
  - Null and alternative hypotheses
  - Type I and Type II error
  - Correlation
    
BAAYEN, Analyzing linguistic data: A practical introduction to statistics using R

* Not (obviously) a good source for intro statistical thinking

STANTON, An Introduction to Data Science

Data Science: Many Skills
* 

GRIES, Quantitative Corpus Linguistics with R

Chapter 5: Some statistics for Corpus Linguistics

* Intro to statistical thinking
  - Variables and their roles in an analysis
  - Variables and their informational value
  - Hypotheses: formulation and operationalization
  - Data analysis
* Categorical dependent variables
  - 1 DV, no IV
  - 1 DV, 1 IV (categorical)
  - 1 DV, 2+ IV (categorical)
* Interval/ ratio-scaled dependent variables
  - 1 DV, no IV
  - 1 DV, 1 IV (categorical)
  - 1 DV, 1 IV (interval/ratio)
  - 1 DV, 2+ IV (mixed)

--&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Gries2013a&#34;&gt;
&lt;p&gt;Gries, ST. 2013. &lt;em&gt;Statistics for Linguistics with R. A Practical Introduction&lt;/em&gt;. 2nd revise.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Johnson:2008&#34;&gt;
&lt;p&gt;Johnson, K. 2008. &lt;em&gt;Quantitative methods in linguistics&lt;/em&gt;. Blackwell Pub.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Munoz2006&#34;&gt;
&lt;p&gt;Muñoz, Carme, ed. 2006. &lt;em&gt;Age and the rate of foreign language learning&lt;/em&gt;. Clevedon: Multilingual Matters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Wickham2017&#34;&gt;
&lt;p&gt;Wickham, Hadley, and Garrett Grolemund. 2017. &lt;em&gt;R for Data Science&lt;/em&gt;. First edit. O’Reilly Media. &lt;a href=&#34;http://r4ds.had.co.nz/&#34; class=&#34;uri&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;The &lt;a href=&#34;http://talkbank.org/&#34;&gt;HomeBank&lt;/a&gt; section of TalkBank is restricted to members only. Membership is free but you will need to contact the repository and request membership.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Note that I’ve added a ‘jitter’ to the data points in this scatter plot to avoid overplotting.&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Project management for scalable data analysis</title>
      <link>https://francojc.github.io/2017/08/31/project-management-for-scalable-data-analysis/</link>
      <pubDate>Thu, 31 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://francojc.github.io/2017/08/31/project-management-for-scalable-data-analysis/</guid>
      <description>&lt;div id=&#34;project-management&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Project management&lt;/h2&gt;
&lt;p&gt;This post can really be seen as an extension of the last post &lt;a href=&#34;https://francojc.github.io/2017/08/14/getting-started-with-r-and-rstudio/&#34;&gt;Getting started with R and RStudio&lt;/a&gt; in that we will be getting to know some more advanced, but indispensable features of RStudio. These features, in combination with some organizational and programming strategies, will enable us to conduct efficient data analysis and set the stage for research is is both scalable and ready for sharing with either collaborators or the research community.&lt;/p&gt;
&lt;p&gt;To understand the value of this approach to project management we need to get a bird’s eye view of the key steps in a data science project. There are three main areas that any research project includes: &lt;strong&gt;data organization&lt;/strong&gt;, &lt;strong&gt;data analysis&lt;/strong&gt;, and &lt;strong&gt;reporting results&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;These three main areas have important subareas as well:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Data organization:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;acquiring data&lt;/em&gt; whether that be from a database or through a download or webscrape&lt;/li&gt;
&lt;li&gt;&lt;em&gt;curating data&lt;/em&gt; so that it will be reliable for subsequent steps in the process&lt;/li&gt;
&lt;li&gt;&lt;em&gt;transforming the data&lt;/em&gt; into a format that will facilitate the analysis of the data including the generation of new variables and measures.&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;2&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Data analysis:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;visualizing data&lt;/em&gt; in summary tables and graphics to gain a better sense of the distribution of the question that we are aiming to learn about.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;statistical tests&lt;/em&gt; to provide confirmation of the distribution(s) that we are investigating and/or a more robust understanding of the relationships between variables in our data&lt;/li&gt;
&lt;/ul&gt;
&lt;ol start=&#34;3&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Reporting results:&lt;/li&gt;
&lt;/ol&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Communicating findings&lt;/em&gt; in an appropriate format for the venue. This can be standard article format, or slides, or as a webpage.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Preparing reproducible results&lt;/em&gt; by ensuring that our work is well documented and capable of being replicated&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By taking these steps into account in the organization of our project, we will be able to work more efficiently and effectively with R and RStudio. In the next section we will get set up with a model template for organizing a data science project. This structure will serve as our base for working in subsequent posts in this series.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;project-structure&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Project structure&lt;/h2&gt;
&lt;p&gt;As a starting point, we will download an existing project that I have created. This project will work as a template for implementing good project management with RStudio. The project template is housed remotely on the code sharing platform &lt;a href=&#34;https://github.com/&#34;&gt;GitHub&lt;/a&gt; which leverages the &lt;a href=&#34;https://git-scm.com/&#34;&gt;&lt;code&gt;git&lt;/code&gt; versioning software&lt;/a&gt; to make local projects remotely accessible. After copying the project to your local machine, we will link RStudio to the project and continue our exploration of the various features available in this software to manage projects.&lt;/p&gt;
&lt;div id=&#34;downloading-the-template&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Downloading the template&lt;/h3&gt;
&lt;p&gt;To download this project template, we will need to set up &lt;code&gt;git&lt;/code&gt; on your machine first. I will have much more to say about &lt;code&gt;git&lt;/code&gt; and GitHub in a later post in the series that will directly concern the process of versioning and sharing reproducible research, but for now we’ll only cover what is needed to get our project template from GitHub. If you are on a Mac, &lt;code&gt;git&lt;/code&gt; is most likely already on your machine. To verify that this is the case you can open up the ‘Terminal.app’ on your machine and type this command at the prompt:&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;which git&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;The ‘Terminal.app’ on Mac, ‘Terminal’ on Linux, and ‘git bash’ on Windows all interface what is called the ‘Shell’, or &lt;a href=&#34;https://en.wikipedia.org/wiki/Command-line_interface&#34;&gt;command-line interface&lt;/a&gt;. This is a interface to your computer not unlike the Console is to R in the R GUI Application or RStudio. There are various environments with particular syntax conventions for working with your computer through this interface, the most common being the ‘Bash’ shell. I encourage you to learn some the &lt;a href=&#34;https://www.davidbaumgold.com/tutorials/command-line/&#34;&gt;basics of using the command-line&lt;/a&gt;.&lt;br /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;If &lt;code&gt;git&lt;/code&gt; is already installed, then a path to this software, similar to the one below, will be returned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;/usr/local/bin/git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If a path is not returned, or you are on a PC, then you will need to download and install the software from the &lt;code&gt;git&lt;/code&gt; homepage. Follow this &lt;a href=&#34;https://git-scm.com/downloads&#34;&gt;link to the &lt;code&gt;git&lt;/code&gt; downloads page&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:git-install-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-31-project-management-for-scalable-data-analysis_files/figure-html/git-install-1-1.png&#34; alt=&#34;Git downloads page.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: Git downloads page.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Download the installer for you operating system and run this installer with the default installation recommendations.&lt;/p&gt;
&lt;p&gt;Now that you have &lt;code&gt;git&lt;/code&gt; on your machine, let’s set some global options that will personalize your software while since we are already working at the command line. If you are on a Mac or Linux, open the ‘Terminal’. If you are on a Windows machine, navigate to the programs menu and open ‘git bash’.&lt;/p&gt;
&lt;p&gt;At the terminal, enter the following commands –replacing ‘Your Name’ and ‘your@email.com’ with your information.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git config --global user.name &amp;#39;Your Name&amp;#39;
git config --global user.email &amp;#39;your@email.com&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, let’s download the project, ‘recipes-project_template’ from &lt;a href=&#34;https://github.com/francojc?tab=repositories&#34;&gt;my personal GitHub repository&lt;/a&gt;. To do this, you will want to first decide where on your machine you will like to store this project. If you are following the Recipe series, I recommend that you create a new directory called &lt;code&gt;Recipes/&lt;/code&gt; somewhere convenient on your hard disk. You can then use this directory to house this and other upcoming projects associated with posts in this series.&lt;/p&gt;
&lt;p&gt;To create this directory, I’ll use the &lt;code&gt;mkdir&lt;/code&gt; command, or ‘make directory’. The &lt;code&gt;~&lt;/code&gt; is a shortcut operator for the current users home directory. On my Mac the full path would be &lt;code&gt;/Users/francojc/Documents/Recipes/&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;mkdir ~/Documents/Recipes/&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Quick tip: When typing a path at the command line you can start typing a directory name and hit the &lt;code&gt;tab&lt;/code&gt; key on your keyboard to autofill the full name. If you hit &lt;code&gt;tab&lt;/code&gt; twice in a row, the &lt;code&gt;bash&lt;/code&gt; shell will list the available subdirectory paths. This can speed up navigation at the command line and help avoid typographical errors.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;Once we have created the main directory &lt;code&gt;Recipes/&lt;/code&gt; to house the repository, we need to navigate to that directory using &lt;code&gt;cd&lt;/code&gt;, or ‘change directory’.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;cd ~/Documents/Recipes/&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Verify that your current working directory is correct by entering &lt;code&gt;pwd&lt;/code&gt;, or ‘path to working directory’ to get the current directory’s path.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;pwd&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The result should print the path to your &lt;code&gt;Recipes/&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;Now we are ready to use &lt;code&gt;git&lt;/code&gt; to copy the remote project from my GitHub repository &lt;code&gt;recipes-project_template&lt;/code&gt; to our current directory. Enter the following command at the terminal prompt.&lt;/p&gt;
&lt;pre class=&#34;bash&#34;&gt;&lt;code&gt;git clone https://github.com/francojc/recipes-project_template.git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should get some information about the download, or clone, that looks something similar to the output below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Cloning into &amp;#39;recipes-project_template&amp;#39;...
remote: Counting objects: 48, done.
remote: Compressing objects: 100% (27/27), done.
remote: Total 48 (delta 21), reused 38 (delta 15), pack-reused 0
Unpacking objects: 100% (48/48), done.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now &lt;code&gt;cd&lt;/code&gt; into the &lt;code&gt;recipes-project_template/&lt;/code&gt; directory that you just cloned into your &lt;code&gt;Recipes/&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;You can now inspect the new directory, subdirectories, and files that now reside in the &lt;code&gt;recipes-project_template/&lt;/code&gt; directory with either at the command line, or with your operating systems file explorer. At the command line you can use the &lt;code&gt;ls&lt;/code&gt;, or ‘list structure’ command like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ls&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You should see the following output.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;README.md   code        figures     log
_pipeline.R data        functions   report&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can now leave the Terminal, or git bash, and return to RStudio. We are now ready to link an R project to our cloned project.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-r-project-within-rstudio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Creating an R Project within RStudio&lt;/h3&gt;
&lt;p&gt;As we have seen, RStudio provides a of host tools for facilitating work with R. A feature that makes working with the sometimes numerous data files, scripts, and other resources more manageable is the ‘R Project’ tool. In a nutshell, this RStudio tool allows us to select a directory where our project files live and effectively group these files and the work we do as a unit. At a basic level it simply helps manage individual projects more easily. As we move on to other posts in this series, and particularly when we discuss creating reproducible research, we will see that this feature will really prove its worth. For now, let’s make the project template an R project and turn to focus on the file and directory structure as it relates to doing efficient and reproducible data analysis in R.&lt;/p&gt;
&lt;p&gt;To link our template to an R Project, start up R and select the ‘New Project…’ dialogue from the RStudio toolbar menu. You will be presented with various options as seen in Figure &lt;a href=&#34;#fig:r-project-1&#34;&gt;2&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-project-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-31-project-management-for-scalable-data-analysis_files/figure-html/r-project-1-1.png&#34; alt=&#34;Options for creating an R Project in RStudio.&#34; width=&#34;400&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Options for creating an R Project in RStudio.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The first option is for starting a project from scratch. The last option is for cloning a project from a versioning repository like GitHub. With versioning software, like &lt;code&gt;git&lt;/code&gt;, on our machine, we can clone and create an R Project in one step. We will make use of this option in future posts now that we have a basic understand of &lt;code&gt;git&lt;/code&gt; and GitHub. For now, however, we want to link the project template we cloned manually using the command line, so select ‘Existing Directory’ from this menu.&lt;/p&gt;
&lt;p&gt;Next navigate to the directory which we cloned either typing the path to the directory, or more conveniently using the ‘Browse’ button. Once we have selected the directory and create the R Project, RStudio will open a new session with our directories and files listed in the Files pane.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-project-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-31-project-management-for-scalable-data-analysis_files/figure-html/r-project-2-1.png&#34; alt=&#34;View of the project template as an R Project.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: View of the project template as an R Project.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You will notice that RStudio has created a file named &lt;code&gt;recipes-project_template.Rproj&lt;/code&gt;. From now on you can navigate to this file using your operating system’s file explorer and open it to return working on this project. Your workspace settings, history, environment variables, etc. will be restored to the last time you were working on the project –more on this later.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;saffolding-for-a-scalable-project&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Saffolding for a scalable project&lt;/h2&gt;
&lt;p&gt;Now let’s turn to the files and directories of our project template and discuss how this structure is associated to the steps listed earlier to conduct a data science project. Below you will see the complete structure of the template.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;├── README.md
├── _pipeline.R
├── code/
│   ├── acquire_data.R
│   ├── analyze_data.R
│   ├── curate_data.R
│   ├── generate_reports.R
│   └── transform_data.R
├── data/
│   ├── derived/
│   └── original/
├── figures/
├── functions/
├── log/
├── recipes-project_template.Rproj
└── report/
    ├── article.Rmd
    ├── bibliography.bib
    ├── slides.Rmd
    └── web.Rmd&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;directories&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Directories&lt;/h3&gt;
&lt;p&gt;This template includes directories for data (&lt;code&gt;data&lt;/code&gt;), code (&lt;code&gt;code&lt;/code&gt;), and communicating findings (&lt;code&gt;report&lt;/code&gt;). These directories are core to your project and where the heavy lifting takes place. The &lt;code&gt;data&lt;/code&gt; and &lt;code&gt;report&lt;/code&gt; directories have important subdirectories that separate key stages in your analysis. &lt;code&gt;data/original&lt;/code&gt; is where the data in its raw form will be stored and &lt;code&gt;data/derived&lt;/code&gt; is where any changes you make to the data for the particular analysis are stored. This distinction is an important one; to safeguard our analysis and to ensure that our analysis is reproducible we do not want to make changes to the original data that are not reflected in the project itself. The subdirectories of &lt;code&gt;report&lt;/code&gt; separate the potential formats that we may use to communicate insight generated from this analysis.&lt;/p&gt;
&lt;p&gt;Before moving on to discuss the files included in the template, let’s discuss the other three supporting directories: &lt;code&gt;figures&lt;/code&gt;, &lt;code&gt;log&lt;/code&gt;, and &lt;code&gt;functions&lt;/code&gt;. You will most likely generate figures in the course of the analysis. Grouping them together in the &lt;code&gt;figures&lt;/code&gt; directory enables us to quickly reference them visually and also include them in any one or all of the reports that may be generated. The &lt;code&gt;log&lt;/code&gt; directory is a convenient and easily identifiable place to document meta aspects of your analysis that will may not picture in your reports. Finally, a directory for housing custom functions you may write to facilitate particular stages of the analysis is provided, &lt;code&gt;functions&lt;/code&gt;. We will soon see how powerful and indispensable custom functions are but for now just let me say that keeping them organized in a separate directory will enhance the legibility of your code and help you take full advantage of their power.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;files&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Files&lt;/h3&gt;
&lt;p&gt;This template also includes various file templates that are associated with the tasks typically performed in a data analysis project. The R scripts in the &lt;code&gt;code/&lt;/code&gt; directory are script templates to carry out the sub-tasks of our three main project steps: organize data; get the original data (&lt;code&gt;acquire_data.R&lt;/code&gt;), clean and prepare key features of the data (&lt;code&gt;curate_data.R&lt;/code&gt;), manipulate the data creating the needed variables and structure for the data analysis (&lt;code&gt;transform_data.R&lt;/code&gt;), data analysis; visualize and perform statistical analyses on the data (&lt;code&gt;analyze_data.R&lt;/code&gt;), and communicating findings; report results in appropriate formats (&lt;code&gt;generate_reports.R&lt;/code&gt;).&lt;/p&gt;
&lt;p&gt;Each of these R scripts has a common structure which is outlined using code commenting. Take a look at the structure of the &lt;code&gt;acquire_data.R&lt;/code&gt; script, copied below:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ABOUT -----------------------------------------------------------

# Description: &amp;lt;The aim of this script&amp;gt;
# Usage: &amp;lt;How to run this script: what input it requires and output produced&amp;gt;
# Author: &amp;lt;Your name&amp;gt;
# Date: &amp;lt;current date&amp;gt;

# SETUP -----------------------------------------------------------

# Script-specific options or packages

# RUN -------------------------------------------------------------

# Steps involved in acquiring and organizing the original data

# LOG -------------------------------------------------------------

# Any descriptives that will be helpful to understand the results of this
# script and how it contributes to the aims of the project

# CLEAN UP --------------------------------------------------------

# Remove all current environment variables
rm(list = ls())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The template shown here leverages code commenting to separate the script into meaningful tasks. The &lt;code&gt;ABOUT&lt;/code&gt; section is where you will provide an overview of the purpose of the script in your project, how to use it, who created it, and when it was created. The &lt;code&gt;SETUP&lt;/code&gt; section provides a space to load any required packages, source any required custom functions, and configure various other options. &lt;code&gt;RUN&lt;/code&gt; is where the bulk of your code will be entered. As it has been stated various times, commenting is a vital part of sound coding practices. It is often helpful not only to comment the particular line of code, which we do by adding the &lt;code&gt;#&lt;/code&gt; symbol to the immediate right of the code and then describe the task, but also to group coding sub-tasks in this section. RStudio provides a tool to create comment sections. You can use this tool by selecting ‘Code &amp;gt; Insert Section…’ or the keyboard shortcut &lt;code&gt;shift + command + R&lt;/code&gt; (Mac) or &lt;code&gt;shift + ctrl + R&lt;/code&gt; (PC). Either approach will trigger a dialogue box to enter the name of the section. Once you have entered the name it will then appear in the section listing, as seen in Figure &lt;a href=&#34;#fig:r-project-3&#34;&gt;4&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-project-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-31-project-management-for-scalable-data-analysis_files/figure-html/r-project-3-1.png&#34; alt=&#34;View of the section listing in RStudio.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: View of the section listing in RStudio.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can use this listing to skip from section to section which can be very helpful as your script becomes more complicated with subsequent code.&lt;/p&gt;
&lt;p&gt;The last two sections &lt;code&gt;LOG&lt;/code&gt; and &lt;code&gt;CLEANUP&lt;/code&gt; are good-housekeeping sections. &lt;code&gt;LOG&lt;/code&gt; is where you can divert any meta-information about the analysis to the &lt;code&gt;log/&lt;/code&gt; directory. This is an important step to take at this point as the last section, &lt;code&gt;CLEANUP&lt;/code&gt;, is where you will remove any of the objects your script has created with the &lt;code&gt;rm(list = ls()&lt;/code&gt; command.&lt;/p&gt;
&lt;p&gt;Although removing objects created is not strictly required, it has two key benefits: it will free up any memory that these objects claim from our R session and it helps keep each script as modular as possible. Freeing up memory after an object is no longer needed is good practice as memory handling in R is not one of the language’s strong points. Striving for modularity speaks more to reproducibility and analysis workflow. If a subsequent step relies on an object generated by a previous script that is held in memory, we must run the previous script in the workflow each time before the next. As the number of tasks increases and as these tasks become more processing intensive, it will lead to an unnecessary loss of computing resources and time. To avoid this scenario, each script in our analysis should only require input that is read from an session-external source; that is from a resource online or from the hard disk. This means that if an object created in a script will be needed a some point in our analysis, it should be written to disk –preferably in a plain-text version.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The last of the three main steps in a data analysis project, ‘Reporting results’, is associated with the file &lt;code&gt;generate_reports.R&lt;/code&gt; in the &lt;code&gt;code/&lt;/code&gt; directory which is tied to the various files in the &lt;code&gt;report/&lt;/code&gt; directory. These later files have the extension &lt;code&gt;.Rmd&lt;/code&gt;, not &lt;code&gt;.R&lt;/code&gt;. This distinction reflects the fact that these files are a special type of R script: an &lt;a href=&#34;http://rmarkdown.rstudio.com/&#34;&gt;RMarkdown script&lt;/a&gt;. RMarkdown is a variant of the popular markup language &lt;a href=&#34;https://en.wikipedia.org/wiki/Markdown&#34;&gt;Markdown&lt;/a&gt;. RMarkdown goes beyond standard Markdown documents in that they allow for the intermingling of code, prose, and graphics to dynamically create reports in &lt;a href=&#34;http://rmarkdown.rstudio.com/pdf_document_format.html&#34;&gt;PDF document format&lt;/a&gt; (&lt;code&gt;report/article/report.Rmd&lt;/code&gt;), &lt;a href=&#34;http://rmarkdown.rstudio.com/ioslides_presentation_format.html&#34;&gt;presentation slides&lt;/a&gt; (&lt;code&gt;report/slides/presentation.Rmd&lt;/code&gt;), and &lt;a href=&#34;http://rmarkdown.rstudio.com/html_document_format.html&#34;&gt;interactive web pages&lt;/a&gt; (&lt;code&gt;report/web/webpage.Rmd&lt;/code&gt;). Data and figures generated in by the R scripts in your analysis can be included in these documents along with citations and a corresponding bibliography sourced from a Bibtex file &lt;code&gt;report/bibliography.bib&lt;/code&gt;.&lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; Together these features a provide powerful tool belt for creating publication quality reports. The &lt;code&gt;generate_reports.R&lt;/code&gt; file simply runs the commands to render these files in their specific formats.&lt;/p&gt;
&lt;p&gt;I have provided rough outlines for each of these RMarkdown output formats. We will explore the details of creating reports later in the series. But for now, I encourage you to browse the &lt;a href=&#34;http://rmarkdown.rstudio.com/gallery.html&#34;&gt;RMarkdown gallery&lt;/a&gt; and explore the &lt;a href=&#34;http://rmarkdown.rstudio.com/articles.html&#34;&gt;documentation&lt;/a&gt; to get a sense of what RMarkdown can do.&lt;/p&gt;
&lt;p&gt;The last two files in this template are the &lt;code&gt;_pipeline.R&lt;/code&gt; script and the &lt;code&gt;README.md&lt;/code&gt; document. &lt;code&gt;README.md&lt;/code&gt; is the file used to describe the project in general terms including the purpose of the project, data sources, analysis methods, and other relevant information to help clarify how to reproduce the research with these project files. The &lt;code&gt;README&lt;/code&gt; file may or may not include the &lt;code&gt;.md&lt;/code&gt; extension. If it does, as in the example in this template, you will have access to the Markdown syntax options to provide word processing style formatting, if needed. If you end up storing you project on a code repository site, such as GitHub, this file will be rendered as a web document and be used as the introduction to your project.&lt;/p&gt;
&lt;p&gt;The &lt;code&gt;_pipeline.R&lt;/code&gt; script is the master script for your analysis. It is a standard R script and includes the same internal commenting sections as the other &lt;code&gt;.R&lt;/code&gt; scripts in the the &lt;code&gt;code/&lt;/code&gt; directory (i.e. &lt;code&gt;ABOUT&lt;/code&gt;, &lt;code&gt;SETUP&lt;/code&gt;, &lt;code&gt;RUN&lt;/code&gt;, &lt;code&gt;LOG&lt;/code&gt;, and &lt;code&gt;CLEANUP&lt;/code&gt;). This script, however, allows you to run the entire project from data to report in sequential order. In the &lt;code&gt;RUN&lt;/code&gt; section you will find sub-steps which call the &lt;code&gt;source()&lt;/code&gt; function on each of our processing scripts. Since each script representing a step in our analysis is modular, only the required input is read and output generated for each script. As logging step-specific information is taken care of in each particular script, the &lt;code&gt;LOG&lt;/code&gt; section in the &lt;code&gt;_pipeline.R&lt;/code&gt; script will most typically only include a call to the &lt;code&gt;sessionInfo()&lt;/code&gt; function which reports details on the operating system and the packages and the versions of the packages used in the analysis. This information is vital for reproducing research as it documents the specific conditions that successfully generated the analysis.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Quick note: there is nothing special about the names of the files in the template. You can edit and modify these file names as you see fit. You should, however, take note of good file naming practices. Names should be descriptive and short. Whitespace is traditionally avoided, but is not explicitly required. I have employed ‘snake case’ here by using an underscore (&lt;code&gt;_&lt;/code&gt;) to mark spaces in file names. There are various style conventions used to avoid whitespace and for other coding practices. I recommend following the suggestions provided by Hadley Wickham in his book &lt;a href=&#34;http://adv-r.had.co.nz/Style.html&#34;&gt;‘Advanced R’&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(Wickham 2014)&lt;/span&gt;. Whatever style you choose, the most important thing is to be consistent.&lt;/p&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;div id=&#34;r-project-sessions&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R Project sessions&lt;/h3&gt;
&lt;p&gt;Once the files and directories are linked to an R Project your workspace settings, command history, and objects can be saved at any point and restored to continue working on the analysis. To see this in action, let’s do a little work with this project template. Let’s run the &lt;code&gt;_pipeline.R&lt;/code&gt; file. There isn’t much to our analysis at this point, as it is just boilerplate material for the most part, but it will serve to highlight how to work with an R Project session. To run this file, open it from the Files pane. It will appear in the Editor pane where we can now use the keyboard shortcut &lt;code&gt;option + command + R&lt;/code&gt; (Mac) or &lt;code&gt;alt + ctrl + R&lt;/code&gt; (PC) to run the entire master script.&lt;/p&gt;
&lt;p&gt;Once you have run the &lt;code&gt;_pipeline.R&lt;/code&gt; script, some new files will appear in your directory structure, seen below.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;├── README.md
├── _pipeline.R
├── code/
│   ├── acquire_data.R
│   ├── analyze_data.R
│   ├── curate_data.R
│   ├── generate_reports.R
│   └── transform_data.R
├── data/
│   ├── derived
│   └── original
├── figures/
├── functions/
├── log/
│   └── session_info.txt
├── recipes-project_template.Rproj
└── report/
    ├── article.Rmd
    ├── article.pdf
    ├── bibliography.bib
    ├── slides.Rmd
    ├── slides.html
    ├── web.Rmd
    └── web.html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new files appear in the &lt;code&gt;log/&lt;/code&gt; and &lt;code&gt;report/&lt;/code&gt; directories. The &lt;code&gt;session_info.txt&lt;/code&gt; file is our log of the session information. The &lt;code&gt;article.pdf&lt;/code&gt;, &lt;code&gt;slides.html&lt;/code&gt;, and &lt;code&gt;web.html&lt;/code&gt; files are the rendered versions of the RMarkdown templates. If you browse to the History tab in the Environment pane you will see that we have one line in our history –the code that ran the &lt;code&gt;_pipeline.R&lt;/code&gt; file. Let’s quit our R session now by closing RStudio. When prompted, choose ‘Save’ from the ‘Quit R session’ dialogue box. Now reopen our R project by either starting RStudio then choosing ‘File &amp;gt; Recent Projects’ in the RStudio toolbar or by navigating to the &lt;code&gt;recipes-project_template.Rproj&lt;/code&gt; file with your operating system’s file explorer and double-clicking it.&lt;/p&gt;
&lt;p&gt;Choosing to save our project before closing RStudio has the effect of taking a snapshot of the current workspace. The files that were open on closing the session are returned to the workspace. Any variables we had in memory and the command history are also returned. The details of this snapshot are stored in the files you will now find at the root of our project directory: &lt;code&gt;.RData&lt;/code&gt; and &lt;code&gt;.Rhistory&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-project-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-31-project-management-for-scalable-data-analysis_files/figure-html/r-project-4-1.png&#34; alt=&#34;View of the R project snapshot files `.RData` and `.Rhistory`.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: View of the R project snapshot files &lt;code&gt;.RData&lt;/code&gt; and &lt;code&gt;.Rhistory&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;You might be wondering why these files are prefixed with &lt;code&gt;.&lt;/code&gt;. Using a period before file names is not specific to RStudio. It is &lt;a href=&#34;https://en.wikipedia.org/wiki/Hidden_file_and_hidden_directory&#34;&gt;a convention used in programming to hide a file from system file explorers&lt;/a&gt;. These types of files are often used for configuration and application resources and are not meant to be edited by the average user.&lt;br /&gt;&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;If you choose not to save the workspace when quitting RStudio, these files will not be generated, if they do not already exist, or they will not be overwritten by the current session if they already exist.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;round-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Round up&lt;/h2&gt;
&lt;p&gt;In this post we have discussed setting up and managing an R Project in RStudio. Along the way I provided a sample template for structuring your data analysis project based on the common steps in data science research. You have seen how this template is associated to each step and learned about some important conventions and guidelines for maintaining an efficient workflow. These principles are fundamental to creating an internally consistent and reproducible project.&lt;/p&gt;
&lt;p&gt;Later on in the series we will discuss project versioning and packaging to make a project fully reproducible for you and future collaborators. We will leave that discussion for now and turn our attention in the next post in the series which addresses one of the main conceptual underpinnings of quantitative research: statistical thinking.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;!-- Ideas for next posts:

* Introduction to statistical thinking
- What is data?
  * Observations
- Informational types
  * The nature of observation
  * Measurements
- Relationships
  * Establishing connections between observations
  * Is a connection reliable?
- Comparisons
  * Generalizing relationships between data collections with similar but unique observationsz

# Sub-task posts

... to working through each of the sub-tasks of the data science workflow focusing on typical contexts and applications for quantitative language and linguistic research. ...

* Acquiring data in R: various sources and types
  - Types of data
    * Curated to uncurated
  - Data sources
    * Locations
    - Files and file types
      * Files and file extensions
      * Plain text
      * Delimited files

* Curating data: cleaning, organizing, and annotating  

* Transforming data: preparing data for analysis  

* Visualization: exploring distributions in graphical and tabular form 

* Analysis:  

* Reporting
  - Creating reports in various formats with RMarkdown
  - Creating reproducible research: project versioning and packaging
    - Project backups, versioning, and sharing
      * git and Github


# Later...




# Book chapters

* Quantitative language research: why does it matter?
- Gains made across the board in quantitative research
- Approaching language research as a quantitative science
- Frequency matters (cognitive rationale for quantitative research)
- Case studies

--&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Wickham2014&#34;&gt;
&lt;p&gt;Wickham, H. 2014. &lt;em&gt;Advanced R&lt;/em&gt;. CRC Press.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Plain text files, in essence, are the &lt;em&gt;lingua franca&lt;/em&gt; of the computing world. They are the type of files that can be readily accessed through a plain-text editor such as ‘TextEdit’ (Mac) or ‘Notepad’ (PC). Importantly these files are not compiled by nor bound to any particular software, such as a document generated by Word or Excel. We will see how to write objects to disk as plain text files in subsequent posts.&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;You can &lt;a href=&#34;http://www.bibtex.org/Using/&#34;&gt;generate your own Bibtex file&lt;/a&gt; or generate one using bibliographic management software such as &lt;a href=&#34;https://blog.mendeley.com/2011/10/25/howto-use-mendeley-to-create-citations-using-latex-and-bibtex/&#34;&gt;Mendeley&lt;/a&gt; or &lt;a href=&#34;http://libguides.mit.edu/c.php?g=176000&amp;amp;p=1159208&#34;&gt;Zotero&lt;/a&gt;&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Getting started with R and RStudio</title>
      <link>https://francojc.github.io/2017/08/14/getting-started-with-r-and-rstudio/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://francojc.github.io/2017/08/14/getting-started-with-r-and-rstudio/</guid>
      <description>&lt;div id=&#34;why-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why R?&lt;/h2&gt;
&lt;p&gt;The R programming language is free software developed with an eye towards statistical computing and data visualization that has has taken off in popularity over the last decade and is now finds itself among the most used programming languages, in &lt;a href=&#34;http://spectrum.ieee.org/computing/software/the-2017-top-programming-languages&#34;&gt;general&lt;/a&gt; and is often the &lt;a href=&#34;https://medium.com/@MarutiTech/which-are-the-popular-languages-for-data-science-8e67fb5ef1ff&#34;&gt;go-to language for data science&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So what’s all the fuss about? Among the things that you will come to love about R, you will be hard pressed to find a more active community surrounding a programming language.&lt;a href=&#34;#fn1&#34; class=&#34;footnoteRef&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; The size and activity of this community means that R stays free, the software improves, and almost anything you are looking to do in your analysis has a user-developed ‘package’ &lt;a href=&#34;#fn2&#34; class=&#34;footnoteRef&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; that facilitates getting any analysis done at various stages in the process. Packages are contributed code from R users that encapsulate a particular and cohesive set of ‘functions’, or sub-tasks; but we will get more into this later in this post and in detail later in the series. &lt;a href=&#34;#fn3&#34; class=&#34;footnoteRef&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The number of R packages grows quickly everyday and now applies to many more tasks that just statistics. To get a sense of this activity you can take a look at an interactive display of current downloads from the R package repository (or store) called &lt;a href=&#34;https://cloud.r-project.org/&#34;&gt;CRAN&lt;/a&gt; that lives on the R Project website.&lt;/p&gt;
&lt;iframe src=&#34;https://gallery.shinyapps.io/087-crandash/?showcase=0&#34; width=&#34;100%&#34; height=&#34;600&#34;&gt;
&lt;/iframe&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;This display, by the way, was created with an R package called &lt;a href=&#34;http://shiny.rstudio.com/&#34;&gt;Shiny&lt;/a&gt;. We’ll get to building interactive websites (like this one) and documents later on in the series.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;R, then, is a widely used open source programming language with a thriving community base that is among the best languages to do the robust and sophisticated analyses that are required for data science. This is an exciting time to be an R programmer and a data scientist, so let’s get started!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-and-installing-r&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading and installing R&lt;/h2&gt;
&lt;p&gt;The beginning, of course, is downloading and installing the software. Follow this link to the R Project website: &lt;a href=&#34;https://www.r-project.org/&#34;&gt;Download R&lt;/a&gt;. This is the home of the R programming language. There are many resources you can find here including a current list of available R packages, resources for getting help (we will see soon, however, that RStudio will have these built right into its user interface), and other various other resources. For now click on the ‘Download R’ link as seen in Figure &lt;a href=&#34;#fig:r-install-1&#34;&gt;1&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-1-1.png&#34; alt=&#34;R Project main page&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 1: R Project main page
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The list of sites here are ‘mirrors’, or alternative servers all over the world where the software is available. Any of these links will do the job, so let’s just select the first mirror ‘&lt;a href=&#34;https://cloud.r-project.org/&#34; class=&#34;uri&#34;&gt;https://cloud.r-project.org/&lt;/a&gt;’ for simplicity sake.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-2-1.png&#34; alt=&#34;Available mirror sites to download R&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 2: Available mirror sites to download R
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next select your operating system. I am working on a Mac so I will select the ‘OS X’ option.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-3-1.png&#34; alt=&#34;Operating system selection&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 3: Operating system selection
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You will now need to scroll down the page a bit and find the link to most recent version of R. The current version at publication is &lt;code&gt;R-3.4.1.pkg&lt;/code&gt;. Download the &lt;code&gt;.pkg&lt;/code&gt; file to your hard drive.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-4-1.png&#34; alt=&#34;Download the most recent `.pkg` file&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 4: Download the most recent &lt;code&gt;.pkg&lt;/code&gt; file
&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;You can download the &lt;code&gt;.pkg&lt;/code&gt; file to any folder on your hard drive. After running this installation file, accept the prompt to move this file to the trash. You will not need it again.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;Once it is on your hard drive, open the file by double-clicking it and follow the default installation instructions.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-5-1.png&#34; alt=&#34;Run the `.pkg` file to install R on your machine.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 5: Run the &lt;code&gt;.pkg&lt;/code&gt; file to install R on your machine.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;To see what get’s installed on your machine you can click the ‘Customize’ link and see the the various pieces of software that are bundled with the &lt;code&gt;.pkg&lt;/code&gt; installer. Go ahead and do that and take a look.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-6&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-6-1.png&#34; alt=&#34;View the default software installed with the R `.pkg` installer.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 6: View the default software installed with the R &lt;code&gt;.pkg&lt;/code&gt; installer.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now you can see the list of software. Let’s focus on two items in the list, seen in Figure &lt;a href=&#34;#fig:r-install-7&#34;&gt;7&lt;/a&gt;. First, you will see the R Framework, which is R itself. Among the other items we see the ‘R GUI’ in the list. This is a basic application interface to R. We’ll take a quick look at that application in the next section to begin our understanding of how to access R through applications and more robust IDEs.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-install-7&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-install-7-1.png&#34; alt=&#34;List of software installed on your machine as part of the installation process.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 7: List of software installed on your machine as part of the installation process.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We won’t spend much time working with the R Application GUI in our series, and quickly move to using RStudio to interface R, but it’s worth knowing that it’s there and it will help us make a point about the distinction between R, the framework, and interfaces to R like this GUI and RStudio. Go ahead and finish the installation and move to the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;working-with-the-r-console-in-the-default-r-application-gui&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Working with the R console in the default R Application GUI&lt;/h2&gt;
&lt;p&gt;Before we get to downloading and working with the RStudio IDE, let’s take a quick look at an alternative way of connecting to R: the R Application GUI. The R Application GUI is installed with together with R itself as mentioned in the previous section. Opening that software we can get our first glimpse at the R console and will run our first line of code.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-gui-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-gui-1-1.png&#34; alt=&#34;A view of the default R Application GUI.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 8: A view of the default R Application GUI.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The console is where we run R interactively. That is to say that the software interprets our code on a line by line basis as we go; a sort of call and response method. The prompt is the line where the computer is ready waiting for the user to enter code to be sent off to the interpreter. Let’s show you what this looks like in action with the most simple of all code; adding &lt;code&gt;1 + 1&lt;/code&gt;. So at the prompt type exactly that, then hit enter/ return and see what happens.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:r-gui-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/r-gui-2-1.png&#34; alt=&#34;Running `1 + 1` at the prompt in the R Application.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 9: Running &lt;code&gt;1 + 1&lt;/code&gt; at the prompt in the R Application.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Admittedly this is not the kind of stuff that will lead you to a romance with R! But it’s our first step and now we know what the console is, what a prompt is, and what an interactive session is.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Why RStudio?&lt;/h2&gt;
&lt;p&gt;So to be clear, R is not an application. It is a programming language that resides deep on your computer. The R Application GUI is merely an interface to that language. The small bit of code we ran on through the console here is a direct link to the interpreter that talks to R itself. This is an important concept as you will see as we turn to working with a more powerful interface to R, RStudio. RStudio will provide a console interface to R as well as host of other extremely helpful features into our GUI experience to write code offline in the form of scripts, manage our scripts and other data resources, view data and plots, get help, and much, much more that will make working with R more efficient.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;downloading-and-installing-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Downloading and installing RStudio&lt;/h2&gt;
&lt;p&gt;To download RStudio, we navigate to the &lt;a href=&#34;https://www.rstudio.com/&#34;&gt;RStudio website’s homepage&lt;/a&gt;. Scroll down a bit and you will see the ‘Download’ button for RStudio.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-install-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-install-1-1.png&#34; alt=&#34;RStudio homepage.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 10: RStudio homepage.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Follow the ‘Download’ button. On this page you will be presented with various versions of the RStudio software. We want the ‘RStudio Desktop - Open source license’ version. Scroll down to the bottom of this table showing the various options you get with the other versions and click the big green ‘Download’ button.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-install-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-install-2-1.png&#34; alt=&#34;List of R Studio versions.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 11: List of R Studio versions.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now select the installer that matches your operating system.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-install-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-install-3-1.png&#34; alt=&#34;List of R Studio installers for various operating systems.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 12: List of R Studio installers for various operating systems.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Again, download this file to any place on your hard drive that you desire. Double-click this file on your computer and follow the instructions to add the application to your machine.&lt;/p&gt;
&lt;p&gt;That’s it. You now have the most current version of R and RStudio on your machine. We’re ready to get familiar with the features of RStudio.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;getting-to-know-rstudio&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Getting to know RStudio&lt;/h2&gt;
&lt;p&gt;Open RStudio. You will see an interface similar to the one below in Figure &lt;a href=&#34;#fig:rstudio-1&#34;&gt;13&lt;/a&gt;. Of course the aesthetics will vary depending on the operating system you are on but there may be other small differences in the tabs in each of the panes. As you work with RStudio you may add new functionality to facilitate certain tasks.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-1-1.png&#34; alt=&#34;First look at RStudio.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 13: First look at RStudio.
&lt;/p&gt;
&lt;/div&gt;
&lt;!-- Keep the description brief, as real understanding will come as we work on pratical applications of programming in R.  --&gt;
&lt;div id=&#34;rstudio-panes&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;RStudio Panes&lt;/h3&gt;
&lt;p&gt;The layout of RStudio includes four main ‘panes’: Console, Editor, Files, and the Environment panes. You already are familiar with the idea of the console, seen here in Figure &lt;a href=&#34;#fig:rstudio-2&#34;&gt;14&lt;/a&gt;. Remember that this is the area that is a direct line between the IDE and the R interpreter. When RStudio is first launched, it will start an R session and this has the effect of reporting some details about the version of R that you are running and the operating system that it is running on.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-2-1.png&#34; alt=&#34;RStudio &amp;quot;Console&amp;quot; pane.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 14: RStudio “Console” pane.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The next logical pane to introduce is the Editor pane, seen in Figure &lt;a href=&#34;#fig:rstudio-3&#34;&gt;15&lt;/a&gt;. Whereas commands written in the console are run on a line by line basis interactively, the Editor will be a useful space for us to view, edit, and write R scripts, as well as other files. Scripts are simply files that contain a series of R commands that we can then run together at once, instead of line by line as we do in the console. This will be the main way we leverage the power of R; by create scripts that run through a data analysis workflow we can then save these scripts as files to run at a future point, continue to develop, revise, and even share them.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-3-1.png&#34; alt=&#34;RStudio &amp;quot;Editor&amp;quot; pane.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 15: RStudio “Editor” pane.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The Files pane has various tabs associated with it. When the ‘Files’ tab is selected we will see files and folders (aka directories) on our machine. As we begin working with R in the next section, we will begin to see how this tab will be extremely useful to see, edit, and delete our scripts, data files, and other associated project files without having to browse our system through as we would normally. There is also a set default tabs: ‘Plots’, ‘Packages’, and ‘Help’ in this pane. Plots will show and export any plots we create during our R session. The Packages tab allows us to manage packages either downloading or installing them. And the Help tab is where we access information about R in general, or particular packages, or functions. You will find that Help is really a godsend as very few R programmers can write code for a project from A to Z without refreshing their memory or exploring documentation on the usage of packages and functions.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-4-1.png&#34; alt=&#34;RStudio &amp;quot;Files&amp;quot; pane.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 16: RStudio “Files” pane.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The last of the four panes is the Environment pane. It includes a set of tabs as well. The main two are ‘Environment’ and ‘History’. The Environment tab allows us to see variables and objects that we create during our session. We haven’t discussed either of these concepts, but rest assured we will get there soon and you will understand how helpful this tab is to efficient R programming. History is just that; a history of the commands that have been sent to the R interpreter. These commands can come from our interactive session in the console or through running a series of commands in a script.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:rstudio-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/rstudio-5-1.png&#34; alt=&#34;RStudio &amp;quot;Environment&amp;quot; pane.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 17: RStudio “Environment” pane.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;So there you have it a brief overview of RStudio panes and tabs. Together these tools will provide us ample resources for just about everything you will ever need to do data analysis with R. In the next section we will begin to see how we can leverage these resources in a basic R session.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;It’s worth noting that RStudio is highly customizable; panes can be customized in appearance, placement, and tabs available. But for now we will leave the default layout to maintain a consistent format throughout this series. If you do want to experiment with the look and feel of RStudio, you can peruse the options through the ‘Tools &amp;gt; Global Options’ in the application dropdown menu at the top of your screen.&lt;/p&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;div id=&#34;r-sessions-in-rstudio&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;R sessions in RStudio&lt;/h3&gt;
&lt;p&gt;To get a basic feel for working with R and RStudio let’s run through a basic example that will highlight each of the main panes and tabs that we covered in the previous section.&lt;/p&gt;
&lt;p&gt;To get started let’s run the same code we ran before in the R Application GUI console but now in the RStudio console. Type the following code in the Console and hit Enter on your keyboard.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;1 + 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;On hitting Enter, the code is sent to the R interpreter which responds with the result; &lt;code&gt;2&lt;/code&gt;. For now ignore the &lt;code&gt;[1]&lt;/code&gt; that prefixes the line where the result is displayed.&lt;/p&gt;
&lt;p&gt;Now let’s run three separate lines of code in the Console in sequence. Take care to enter this and all subsequent code input correctly computers do not tolerate typos. Remember you’re the brains here, the computer is the brawn!&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;Quick tip: You can add the assignment operator &lt;code&gt;&amp;lt;-&lt;/code&gt; via a keyboard shortcut by hitting &lt;code&gt;option + -&lt;/code&gt; (Mac) and &lt;code&gt;alt + -&lt;/code&gt; (PC).&lt;/p&gt;

&lt;/div&gt;

&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x &amp;lt;- 1:26&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;y &amp;lt;- letters&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste(x, &amp;quot;-&amp;quot;, y)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You will notice that the first two commands did not return anything. This is because we sent the results from each of these commands to the variables &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;, respectively. A variable is a data container that is named. This container, or variable, holds the result in memory and gives us access to the result when we use the variable name later on. As you will soon see, you will inevitably create a number of variables in any given data analysis. There are two ways to see a listing of variables you have created. The first can be done in the Console by typing the function &lt;code&gt;ls()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ls()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;x&amp;quot; &amp;quot;y&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The second is to browse to the Environment pane under the Environment tab. You will see that the Environment tab provides much more information that just the names of the variables in memory. It also indicates the type of each variable, its dimensions (in this case length as we are working with vectors), its memory size, and a summary of the values contained within.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-1&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-1-1.png&#34; alt=&#34;Viewing variables in the Environment tab.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 18: Viewing variables in the Environment tab.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In the third command we make use of the variables &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt;: pasting (with the built-in, or ‘base R’, function &lt;code&gt;paste()&lt;/code&gt;) the results from &lt;code&gt;x&lt;/code&gt; (a series of numbers from 1 to 26) and &lt;code&gt;y&lt;/code&gt; (the letters of the alphabet) together with a hyphen as a separator.&lt;/p&gt;
&lt;p&gt;If that was the result we were looking for then great. Job done. Imagine, however, that we wanted the result to return contiguous ‘number-hyphen-letter’ strings, like &lt;code&gt;1-a&lt;/code&gt;. Is that possible? Yes, it is. But don’t take my word for it, let’s find out using RStudio’s Help resources. Again, there are two ways to do this. The first is by inputting the code &lt;code&gt;?paste&lt;/code&gt; in the Console.&lt;/p&gt;
&lt;p&gt;By appending the &lt;code&gt;?&lt;/code&gt; operator to a function, package, or dataset name the Help tab in the Files pane is opened to the R documentation page.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-2&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-2-1.png&#34; alt=&#34;Viewing R documentation in the Help tab.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 19: Viewing R documentation in the Help tab.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The second approach is to manually browse to the Help tab and search for the function &lt;code&gt;paste&lt;/code&gt;. Either works, you might find yourself alternating between the two.&lt;/p&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;In some cases you might not remember the name of the function, package, or dataset that you want to find documentation for. For a more general search you can use the &lt;code&gt;??&lt;/code&gt; operator instead of the &lt;code&gt;?&lt;/code&gt;. Or as an alternative use the search function in the Help tab.&lt;/p&gt;

&lt;/div&gt;

&lt;p&gt;Back to our code. The R documentation shows that &lt;code&gt;paste()&lt;/code&gt; can take an optional sub-command, or argument, that will allow us to choose how our paste variables are separated. With this knowledge in hand we can update our code. We will use the argument &lt;code&gt;sep = &amp;quot;&amp;quot;&lt;/code&gt; to remove white space between the concatenated elements like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;paste(x, &amp;quot;-&amp;quot;, y, sep = &amp;quot;&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] &amp;quot;1-a&amp;quot;  &amp;quot;2-b&amp;quot;  &amp;quot;3-c&amp;quot;  &amp;quot;4-d&amp;quot;  &amp;quot;5-e&amp;quot;  &amp;quot;6-f&amp;quot;  &amp;quot;7-g&amp;quot;  &amp;quot;8-h&amp;quot;  &amp;quot;9-i&amp;quot;  &amp;quot;10-j&amp;quot;
## [11] &amp;quot;11-k&amp;quot; &amp;quot;12-l&amp;quot; &amp;quot;13-m&amp;quot; &amp;quot;14-n&amp;quot; &amp;quot;15-o&amp;quot; &amp;quot;16-p&amp;quot; &amp;quot;17-q&amp;quot; &amp;quot;18-r&amp;quot; &amp;quot;19-s&amp;quot; &amp;quot;20-t&amp;quot;
## [21] &amp;quot;21-u&amp;quot; &amp;quot;22-v&amp;quot; &amp;quot;23-w&amp;quot; &amp;quot;24-x&amp;quot; &amp;quot;25-y&amp;quot; &amp;quot;26-z&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With time you will become more accustomed to reading and making sense of the R documentation. For now, however, it is sufficient to have learned how and where to access this documentation.&lt;/p&gt;
&lt;p&gt;The previous code we have run is short and simple. Working with the Console is great for this type of quick and dirty exploring, or doing some introspection of variables using &lt;code&gt;ls()&lt;/code&gt; or the help operator &lt;code&gt;?&lt;/code&gt; to view the R help documentation. However, data analysis will involve many more lines of code and using the Console directly will become cumbersome. A more convenient way to write code is to use the Editor pane.&lt;/p&gt;
&lt;p&gt;Let’s run through a more involved and practical example of creating a basic word frequency analysis. Before we get to the code below, let me introduce you to installing and managing R packages. As we have seen a couple times now there is a Console-based method and an GUI-based method. This time I will start with the GUI method as it is very convenient and tends to be the method most use. First step is to open the Packages tab in the Files pane, seen below.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-3&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-3-1.png&#34; alt=&#34;The Packages tab.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 20: The Packages tab.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You will see a list of the R packages that are already installed on your machine. The base installation of R comes with a default set so you will already see some packages listed. However, you may not see all of the packages that appear in Figure &lt;a href=&#34;#fig:R-basic-3&#34;&gt;20&lt;/a&gt; if you have not already manually installed new packages (for example the &lt;code&gt;acs&lt;/code&gt; package for accessing US Census data).&lt;/p&gt;
&lt;p&gt;Let’s install a few packages we need for the upcoming code: &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, and &lt;code&gt;tidytext&lt;/code&gt;. Installing packages with the Packages tab is easy. First, click on the ‘Install’ button within the tab.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-4&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-4-1.png&#34; alt=&#34;The packages installation dialogue box.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 21: The packages installation dialogue box.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Type the names &lt;code&gt;dplyr&lt;/code&gt;, &lt;code&gt;ggplot2&lt;/code&gt;, and &lt;code&gt;tidytext&lt;/code&gt; into the ‘Packages’ field leaving the other default configuration fields. You will notice as you type the package names, RStudio will pattern match the name which can be helpful to make sure you type the names correctly. Once you have the names entered, click the ‘Install’ button. At this point RStudio will run the installation code for these packages. As they install there will be quite a bit of output, some of it in red font, in the Console. When the installation is complete the prompt &lt;code&gt;&amp;gt;&lt;/code&gt; at the Console will appear; ready to take another command.&lt;/p&gt;
&lt;p&gt;The Console approach leverages the function &lt;code&gt;install.packages()&lt;/code&gt;. To find out more about how to use this function, I encourage you to look at the R documentation using &lt;code&gt;?install.packages&lt;/code&gt;. I will leave this as an exercise for you to complete. Now back to our example code that we will enter in the Editor pane.&lt;/p&gt;
&lt;p&gt;Copy and paste the following code into the Editor pane.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(dplyr) # data manipulation
library(ggplot2) # package for generating a word frequency plot
library(tidytext) # package for doing a word frequency analysis

text &amp;lt;- c(&amp;quot;The Fulton County Grand Jury said Friday an investigation of Atlanta&amp;#39;s recent primary election produced no evidence that any irregularities took place.&amp;quot;,
&amp;quot;The jury further said in term-end presentments that the City Executive Committee, which had over-all charge of the election, deserves the praise and thanks of the City of Atlanta for the manner in which the election was conducted.&amp;quot;,
&amp;quot;The September-*october term jury had been charged by Fulton Superior Court Judge Durwood Pye to investigate reports of possible irregularities in the hard-fought primary which was won by Mayor-nominate Ivan Allen Jr..&amp;quot;,
&amp;quot;Only a relative handful of such reports was received, the jury said, considering the widespread interest in the election, the number of voters and the size of this city.&amp;quot;) # first 4 lines from the Brown Corpus

text_df &amp;lt;- data.frame(line = 1:4, text = text) # create a tabular dataset with the columns `line` and `text`

text.word.freq &amp;lt;- unnest_tokens(tbl = text_df, input = text, output = words) %&amp;gt;% # tokenize `text` into `words`
  count(words, sort = TRUE) %&amp;gt;% # count `words` and sort them
  head(10) # return only the first ten lines in the dataset

ggplot(data = text.word.freq, aes(x = reorder(words, desc(n)), y = n)) + geom_bar(stat = &amp;quot;identity&amp;quot;) + labs(x = &amp;quot;Words&amp;quot;, y = &amp;quot;Count&amp;quot;, title = &amp;quot;Word frequency plot&amp;quot;) # plot the `words` on the x-axis and the count `n` on the y-axis using a bar plot ordered by `n`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your code should look something similar to what you see in Figure &lt;a href=&#34;#fig:R-basic-5&#34;&gt;22&lt;/a&gt;. Note that I have resized the Editor pane to view most of the code.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-5&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-5-1.png&#34; alt=&#34;Code for a basic word frequency analysis in the Editor pane.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 22: Code for a basic word frequency analysis in the Editor pane.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We can run the code in the Editor pane either line by line or as a complete script. Running code line by line can be useful when you are composing a script and want to test the results incrementally. To do this you move your cursor to the line you would like to run and then simply hit the keystroke &lt;code&gt;command + enter&lt;/code&gt; (Mac) or &lt;code&gt;ctrl + enter&lt;/code&gt; (PC). Run line 1 and see what happens!&lt;/p&gt;
&lt;p&gt;Line 1 loads the &lt;code&gt;dplyr&lt;/code&gt; package from our package library with the command &lt;code&gt;library(dplyr)&lt;/code&gt;. If you resize the Console pane you will see that the command was run and resulted in some details about the package printed to the Console. We also notice that the cursor has moved to the next line in the Editor pane, ready for us to run this line.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-6&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-6-1.png&#34; alt=&#34;Running the first line of our basic word frequency analysis.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 23: Running the first line of our basic word frequency analysis.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;In this script I’ve also added comments to each line of code describing what each command does in our script. Any time R finds a &lt;code&gt;#&lt;/code&gt; symbol it ignores everything to the right on the same line. We can then use plain language to annotate our code. Using commenting is a key best practice for coding in any programming language as it will make your code more legible to other users as well as the future you who might come back to this code sometime down the road to realize you have forgotten what your code does!&lt;/p&gt;
&lt;p&gt;Returning to running our code from the Editor, we can also run multiple lines, or even the entire script from the Editor pane in a similar fashion by selecting multiple lines, or all the lines and using the previous keystroke (&lt;code&gt;command + enter&lt;/code&gt;, or &lt;code&gt;ctrl + enter&lt;/code&gt;). RStudio provides a button ‘Run’ that can be used to run a script line by line or the ‘Source’ button to run the entire script.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-7&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-7-1.png&#34; alt=&#34;Running the entire script using the RStudio tool Source.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 24: Running the entire script using the RStudio tool Source.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Go ahead and run the entire script now with by clicking ‘Source’. The script will be automatically sent line by line sequentially to the Console. The results of this script generate a word frequency plot for the first four lines from the well-known &lt;a href=&#34;https://en.wikipedia.org/wiki/Brown_Corpus&#34;&gt;Brown Corpus&lt;/a&gt;. The Plots tab in the Files pane will automatically open revealing our plot.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-8&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-8-1.png&#34; alt=&#34;Resulting plot from our basic word frequency analysis script.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 25: Resulting plot from our basic word frequency analysis script.
&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;alert alert-note&#34;&gt;
  &lt;p&gt;There are many other options for running code from the Editor pane using keyboard shortcuts. Explore the ‘Code &amp;gt; Run region’ dropdown from the RStudio menu bar for more information.&lt;/p&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;div id=&#34;saving-our-work&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Saving our work&lt;/h3&gt;
&lt;p&gt;At this point we may want to save the code to our hard drive to make sure we don’t lose our work, or to move on and write some other code. To save this R script navigate to the RStudio tool menu ‘File &amp;gt; Save’ or hit the keyboard shortcut &lt;code&gt;command + s&lt;/code&gt; (Mac) or &lt;code&gt;ctrl + s&lt;/code&gt; (PC). The next step is to choose where to save this file. Select a directory for this file to live. For now you can choose any directory you feel fit. As we move forward in this series and in more involved projects that you will work on, however, it’s best to do some organizational planning upfront to set up your main project directory, sub-directories, and so on so that it is clear where to save each type of file. This topic will be covered in an upcoming Recipe post dealing with project management using the RStudio ‘Projects’ feature.&lt;/p&gt;
&lt;p&gt;For testing purposes, let’s save the file within the current working directory inside a directory we will create named &lt;code&gt;getting_started/&lt;/code&gt;. What is the working directory? Well, it is the place that RStudio regards as “Home base” on your hard drive. To find out what this is, enter the function &lt;code&gt;getwd()&lt;/code&gt; at the console. R will return a path to the current working directory. On my machine the path is &lt;code&gt;/Users/francojc/Documents/Recipes&lt;/code&gt;. This notation is describes the hierarchical scheme of directories. My current working directory, then is the &lt;code&gt;Recipes/&lt;/code&gt; directory which is located inside the &lt;code&gt;Documents/&lt;/code&gt; directory which itself is located within my home directory &lt;code&gt;francojc/&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s go ahead and open the ‘File &amp;gt; Save’ tool RStudio menu and name our file &lt;code&gt;basic_frequency_analysis.R&lt;/code&gt;. The use of &lt;code&gt;_&lt;/code&gt; here is to avoid white space in file and directory names. This is good practice as working with paths in programming can be complicated by white space in some environments. So it’s good practice to avoid white space. There are various styles that are employed in programming, &lt;a href=&#34;https://en.wikipedia.org/wiki/Programming_style&#34;&gt;generally&lt;/a&gt;, and in &lt;a href=&#34;http://adv-r.had.co.nz/Style.html&#34;&gt;R programming specifically&lt;/a&gt;. Just like commenting code, as mentioned previously, adopting accepted style guidelines can increase your code’s legibility for you and those who may work with code you share.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-9&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-9-1.png&#34; alt=&#34;&amp;quot;Save&amp;quot; dialogue in RStudio.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 26: “Save” dialogue in RStudio.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once we have saved our file in our working directory, it will now appear in the Files tab in RStudio. From this tab you can move, rename, and delete files as well as create, rename, and delete directories as well. It’s also worth pointing out that the path to our working directory is visible in this Files tab between the working directory listing and the button toolbar. This is a nice feature to see where the files and directories live on your machine without resorting to the OS file explorer.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-10&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-10-1.png&#34; alt=&#34;Viewing files in the Files tab.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 27: Viewing files in the Files tab.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Let’s create our &lt;code&gt;getting_started/&lt;/code&gt; directory inside of our working directory to house this file. Click the ‘New Folder’ button inside the Files tab and name the new directory. It will now appear in our listing. To move our file inside of this directory we can use the OS to manually move the file, but RStudio again provides tools to do this. Select the checkbox beside the file &lt;code&gt;basic_frequency_analysis.R&lt;/code&gt;, then select ‘Move…’ from the ‘More’ dropdown menu.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-11&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-11-1.png&#34; alt=&#34;Moving a file to a new directory in the Files tab.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 28: Moving a file to a new directory in the Files tab.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;After you make the move, RStudio will quickly ask you if you want to close the &lt;code&gt;basic_frequency_analysis.R&lt;/code&gt; script as it no longer exists. It does exist, just not in the same location as before. This underscores the importance of paths in programming and programming tools like RStudio. It is therefore of utmost importance to be aware of the paths to files and directories. Luckily, RStudio provides us ample ways to monitor the paths to working files and directories!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;closing-an-r-session&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Closing an R session&lt;/h3&gt;
&lt;p&gt;At this point let’s say it’s time to close our session and quit RStudio. You can do this by simply navigating to the RStudio tool menu ‘File &amp;gt; Quit session…’. You will be presented with a dialogue box to save the workspace or not.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-12&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-12-1.png&#34; alt=&#34;Quiting an R session.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 29: Quiting an R session.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;We can choose not to save the workspace and our files will be preserved (as long as they have been previously saved to the hard disk). What we lose, however, are the variables and history that RStudio has in memory at the current moment in our session. If you want to begin your next session with these variables and history loaded from the get-go, then we will want to save the workspace. Let’s choose to save the workspace to see this in action. After quitting RStudio, restart the application. Because we had chosen to save the workspace we now have our variables and history in this new R session. You can view them in the Environment pane. If you navigate to the working directory in the Files tab in the Files tab you will also see a couple new files have been added to our files and directory list: &lt;code&gt;.RData&lt;/code&gt; and &lt;code&gt;.Rhistory&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;&lt;span id=&#34;fig:R-basic-13&#34;&gt;&lt;/span&gt;
&lt;img src=&#34;https://francojc.github.io/post/2017-08-14-getting-started-with-r-and-rstudio_files/figure-html/R-basic-13-1.png&#34; alt=&#34;Workspace files `.RData` and `.Rhistory`.&#34; width=&#34;100%&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;
Figure 30: Workspace files &lt;code&gt;.RData&lt;/code&gt; and &lt;code&gt;.Rhistory&lt;/code&gt;.
&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;When you restart another session, R will look for these files and load them into the workspace for you to pick up and continue using. If you choose to quit an R session without saving the workspace these files will not be created, or in the case they already exist from a previous workspace session, will not be overwritten and the earlier variables and history will be loaded.&lt;/p&gt;
&lt;div class=&#34;alert alert-warning&#34;&gt;
  &lt;p&gt;If you browse the working directory of a session with your operating system’s file explorer you may not see these files listed. Do not be alarmed. By default an operating system hides all files that start with &lt;code&gt;.&lt;/code&gt; as a convenience to user. There are many of these types of files hanging around your OS. They often contain application-specific configuration information which usually do not require direct editing.&lt;/p&gt;

&lt;/div&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;round-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Round up&lt;/h2&gt;
&lt;p&gt;We have covered a lot of ground in this post. You should now have a working understanding of how R and RStudio are related and the various panes that are available to develop code and manage your workspace. We have also scratched the surface on some topics that will be covered in more depth in future posts including variables, paths, and workspace and project management, to name a few. The next post in the Recipe series ‘Project management for scalable data analysis’ will deal with many of these topics as we set the foundation for working with more complex and realistic analyses.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Follow this link to &lt;a href=&#34;http://rapporter.net/custom/R-activity/#score/6&#34;&gt;see estimated figures of the number of R users around the world&lt;/a&gt;&lt;a href=&#34;#fnref1&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Think of Steve Jobs’ famous sound bite: ‘There’s an app for that’, just replace ‘app’ with ‘package’ in the case of R.&lt;a href=&#34;#fnref2&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;Don’t fret over some of the terminology here, we will come back to these terms later on with detailed description and examples.&lt;a href=&#34;#fnref3&#34;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Introducing the Recipe series</title>
      <link>https://francojc.github.io/2017/08/03/introducing-the-recipe-series/</link>
      <pubDate>Thu, 03 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://francojc.github.io/2017/08/03/introducing-the-recipe-series/</guid>
      <description>&lt;div id=&#34;the-recipe-series-an-overview&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Recipe series: an overview&lt;/h2&gt;
&lt;p&gt;My goal in this series is to explore the ‘why’ and the ‘how’ of doing quantitative language research. The content of this series will, in large part, overlap with resources available on doing Data Science, generally (see &lt;span class=&#34;citation&#34;&gt;(Wickham and Grolemund 2017)&lt;/span&gt;), or in field-specific areas and domains &lt;span class=&#34;citation&#34;&gt;(Beckerman, Childs, and Petchey 2017; Hodeghatta and Nayak 2016; Perlin 2017)&lt;/span&gt;. However, this series will focus exclusively on issues and methods concerning language data and linguistic analyses through practical data sources and realistic examples.&lt;/p&gt;
&lt;p&gt;I will assume little computing, programming, or statistical knowledge, but I hope to provide useful information for even the more experienced researchers and practicioners. Doing quantitative language research does not require programming skills, as there are many tools and &lt;a href=&#34;https://en.wikipedia.org/wiki/Graphical_user_interface&#34;&gt;graphical user interfaces&lt;/a&gt; (GUI) available to do basic to even quite complex language analyses without these skills, but programming, for most practicing data scientists, is a more efficient and effective strategy for approaching data analysis. This series will make use of the &lt;a href=&#34;https://www.r-project.org/about.html&#34;&gt;R programming language&lt;/a&gt; and the powerful &lt;a href=&#34;https://en.wikipedia.org/wiki/Integrated_development_environment&#34;&gt;Integrated Development Environment&lt;/a&gt; (IDE) &lt;a href=&#34;https://www.rstudio.com/products/RStudio/&#34;&gt;RStudio&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Through R and RStudio I will cover organizational topics like software installation, accessing files, and project management all the way through reporting results and creating reproducible research. Along the way I will cover the fundamental concepts and methods for statistical language analysis including data acquisition, preparation, transformation, and visualization as well as data modeling for hypothesis testing and exploratory and predictive analysis.&lt;/p&gt;
&lt;p&gt;As a primary goal this series represents an effort to document and share the knowledge and skills I have acquired over the years with those that have an interest in quantitative language and/or programming with R. There is, however, a second, more selfish goal: I aim to learn a lot in the process through consolidating and conveying my knowledge as well as recieving comments, feedback, and corrections from the community. To this end, please don’t hesitate to contact me with ideas for posts or suggestions or alternative approaches to existing posts.&lt;/p&gt;
&lt;p&gt;OK. With that in mind, let’s get staRted!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references&#34;&gt;
&lt;div id=&#34;ref-Beckerman2017&#34;&gt;
&lt;p&gt;Beckerman, Andrew P., Dylan Z. Childs, and Owen L. Petchey. 2017. &lt;em&gt;Getting Started with R: An Introduction for Biologists&lt;/em&gt;. Second edi. Oxford University Press.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Hodeghatta2016&#34;&gt;
&lt;p&gt;Hodeghatta, Umesh R, and Umesha Nayak. 2016. &lt;em&gt;Business Analytics Using R - A Practical Approach&lt;/em&gt;. First edit. Apress.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Perlin2017&#34;&gt;
&lt;p&gt;Perlin, Marcelo S. 2017. &lt;em&gt;Processing and Analyzing Financial Data with R&lt;/em&gt;. First edit. Agencia Brasileira de ISBN.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Wickham2017&#34;&gt;
&lt;p&gt;Wickham, Hadley, and Garrett Grolemund. 2017. &lt;em&gt;R for Data Science&lt;/em&gt;. First edit. O’Reilly Media. &lt;a href=&#34;http://r4ds.had.co.nz/&#34; class=&#34;uri&#34;&gt;http://r4ds.had.co.nz/&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
