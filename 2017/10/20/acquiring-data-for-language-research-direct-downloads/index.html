<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 2.4.0">
  <meta name="generator" content="Hugo 0.49" />
  <meta name="author" content="Jerid Francom">

  
  
  
  
    
  
  <meta name="description" content="In this post, I will provide an overview of the first of three common strategies for acquiring corpus data in R: accessing corpus data from data repositories and individual sites. I will cover acquiring data from different sources and introduce you to the R code that will help speed the process, maintain consistency in our data, and set the stage for a reproducible workflow.">

  
  <link rel="alternate" hreflang="en-us" href="https://francojc.github.io/2017/10/20/acquiring-data-for-language-research-direct-downloads/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#0095eb">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
      
    

    

    

  

  
  
  <link rel="stylesheet" href=//fonts.googleapis.com/css?family=Lato:400,700|Merriweather|Roboto+Mono>
  

  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/my-styles.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-57189160-2', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://francojc.github.io/index.xml" type="application/rss+xml" title="francojc ⟲">
  <link rel="feed" href="https://francojc.github.io/index.xml" type="application/rss+xml" title="francojc ⟲">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://francojc.github.io/2017/10/20/acquiring-data-for-language-research-direct-downloads/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="francojc ⟲">
  <meta property="og:url" content="https://francojc.github.io/2017/10/20/acquiring-data-for-language-research-direct-downloads/">
  <meta property="og:title" content="Acquiring data for language research (1/3): direct downloads | francojc ⟲">
  <meta property="og:description" content="In this post, I will provide an overview of the first of three common strategies for acquiring corpus data in R: accessing corpus data from data repositories and individual sites. I will cover acquiring data from different sources and introduce you to the R code that will help speed the process, maintain consistency in our data, and set the stage for a reproducible workflow.">
  
  
    
  <meta property="og:image" content="https://francojc.github.io/img/icon-192.png">
  <meta property="og:locale" content="en-us">
  
  <meta property="article:published_time" content="2017-10-20T00:00:00&#43;00:00">
  
  <meta property="article:modified_time" content="2017-10-20T00:00:00&#43;00:00">
  

  

  

  <title>Acquiring data for language research (1/3): direct downloads | francojc ⟲</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">francojc ⟲</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#about">
            
            <span>Home</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#publications">
            
            <span>Publications</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#talks">
            
            <span>Talks</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#posts">
            
            <span>Posts</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#projects">
            
            <span>Projects</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#teaching">
            
            <span>Teaching</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Contact</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  





  <div class="article-container">
    <h1 itemprop="name">Acquiring data for language research (1/3): direct downloads</h1>

    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Jerid Francom">
  </span>
  

  <span class="article-date">
    
    <meta content="2017-10-20 00:00:00 &#43;0000 UTC" itemprop="datePublished">
    <time datetime="2017-10-20 00:00:00 &#43;0000 UTC" itemprop="dateModified">
      Fri, Oct 20, 2017
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Jerid Francom">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    13 min read
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    
    <a href="/categories/r/">R</a>, 
    
    <a href="/categories/recipe/">Recipe</a>
    
  </span>
  
  

  
  

  

</div>


    <div class="article-style" itemprop="articleBody">
      <link href="/rmarkdown-libs/pagedtable/css/pagedtable.css" rel="stylesheet" />
<script src="/rmarkdown-libs/pagedtable/js/pagedtable.js"></script>


<p>There are three main ways to acquire corpus data using R that I will introduce you to: <strong>direct download</strong>, <strong>package interfaces</strong>, and <strong>web scraping</strong>. In this post we will start by directly downloading a corpus as it is the most straightforward process for the novice R programmer and incurs the least number of steps. Along the way I will introduce some key R coding concepts including control statements and custom functions.</p>
<div class="alert alert-note">
  <p>The following code is available on GitHub <code>recipes-acquiring_data</code> and is built on the <code>recipes-project_template</code> I have discussed in detail <a href="https://francojc.github.io/2017/08/31/project-management-for-scalable-data-analysis/">here</a> and made accessible <a href="https://github.com/francojc/recipes-project_template.git">here</a>. I encourage you to follow along by downloading the <code>recipes-project_template</code> with <code>git</code> from the Terminal or create a new RStudio R Project and select the “Version Control” option.</p>

</div>

<!-- TODO: add {#anchor} below -->
<div id="direct-downloads" class="section level2">
<h2>Direct downloads</h2>
<p>Published corpus data found in repositories or individual sources are usually the easiest to start working with as it is generally a matter of identifying a resource to download and then downloading it with R. OK, there’s a little more involved, but that’s the basic idea.</p>
<p>Let’s take a look at how this works starting with the a sample from the Switchboard Corpus, a corpus of 2,400 telephone conversations by 543 speakers. First we navigate to the site with a browser and download the file that we are looking for. In this case I found the Switchboard Corpus on the <a href="http://www.nltk.org/nltk_data/">NLTK data repository site</a>. More often than not this file will be some type of compressed archive file with an extension such as <code>.zip</code> or <code>.tz</code>, which is the case here. Archive files make downloading multiple files easy by grouping files and directories into one file. In R we can used the <code>download.file()</code> function from the base R library<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. There are a number of <strong>arguments</strong> that a function may require or provide optionally. The <code>download.file()</code> function minimally requires two: <code>url</code> and <code>destfile</code>. That is the file to download and the location where it is to be saved to disk.</p>
<pre class="r"><code># Download .zip file and write to disk
download.file(url = &quot;https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip&quot;, destfile = &quot;data/original/switchboard.zip&quot;)</code></pre>
<p>Once an archive file is downloaded, however, the file needs to be ‘decompressed’ to reveal the file structure. The file we downloaded is located on our disk at <code>data/original/switchboard.zip</code>. To decompress this file we use the <code>unzip()</code> function with the arguments <code>zipfile</code> pointing to the <code>.zip</code> file and <code>exdir</code> specifying the directory where we want the files to be extracted to.</p>
<div class="alert alert-note">
  <p>I encourage you to use the <code>TAB</code> key to expand the list of options of a function to avoid having to remember the arguments of a function and also to avoid typos. After typing the name of the function and opening <code>(</code> hit <code>TAB</code> to view and select the argument(s) you want. Furthermore, the <code>TAB</code> key can also help you expand paths to files and directories. Note that the expansion will default to the current working directory.</p>

</div>

<pre class="r"><code># Decompress .zip file and extract to our target directory
unzip(zipfile = &quot;data/original/switchboard.zip&quot;, exdir = &quot;data/original/&quot;)</code></pre>
<p>The directory structure of <code>data/</code> now should look like this:</p>
<pre><code>data/
├── derived
└── original
    ├── switchboard
    │   ├── README
    │   ├── discourse
    │   ├── disfluency
    │   ├── tagged
    │   ├── timed-transcript
    │   └── transcript
    └── switchboard.zip

3 directories, 7 files</code></pre>
<p>At this point we have acquired the data programmatically and with this code as part of our workflow anyone could run this code and reproduce the same results. The code as it is, however, is not ideally efficient. Firstly the <code>switchboard.zip</code> file is not strictly needed after we decompress it and it occupies disk space if we keep it. And second, each time we run this code the file will be downloaded from the remote serve leading to unnecessary data transfer and server traffic. Let’s tackle each of these issues in turn.</p>
<p>To avoid writing the <code>switchboard.zip</code> file to disk (long-term) we can use the <code>tempfile()</code> function to open a temporary holding space for the file. This space can then be used to store the file, unzip it, and then the temporary file will be destroyed. We assign the temporary space to an R object we will name <code>temp</code> with the <code>tempfile()</code> function. This object can now be used as the value of the argument <code>destfile</code> in the <code>download.file()</code> function. Let’s also assign the web address to another object <code>url</code> which we will use as the value of the <code>url</code> argument.</p>
<pre class="r"><code># Create a temporary file space for our .zip file
temp &lt;- tempfile()
# Assign our web address to `url`
url &lt;- &quot;https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip&quot;
# Download .zip file and write to disk
download.file(url, temp)</code></pre>
<div class="alert alert-note">
  <p>In the previous code I’ve used the values stored in the objects <code>url</code> and <code>temp</code> in the <code>download.file()</code> function without specifying the argument names –only providing the names of the objects. R will assume that values of a function map to the ordering of the arguments. If your values do not map to ordering of the arguments you are required to specify the argument name and the value. To view the ordering of objects hit <code>TAB</code> after entering the function name or consult the function documentation by prefixing the function name with <code>?</code> and hitting <code>ENTER</code>.</p>

</div>

<p>At this point our downloaded file is stored temporarily on disk and can be accessed and decompressed to our target directory using <code>temp</code> as the value for the argument <code>zipfile</code> from the <code>unzip()</code> function. I’ve assigned our target directory path to <code>target_dir</code> and used it as the value for the argument <code>exdir</code> to prepare us for the next tweak on our approach.</p>
<pre class="r"><code># Assign our target directory to `target_dir`
target_dir &lt;- &quot;data/original/&quot;
# Decompress .zip file and extract to our target directory
unzip(zipfile = temp, exdir = target_dir)</code></pre>
<p>Our directory structure now looks like this:</p>
<pre><code>data/
├── derived
└── original
    └── switchboard
        ├── README
        ├── discourse
        ├── disfluency
        ├── tagged
        ├── timed-transcript
        └── transcript

3 directories, 6 files</code></pre>
<p>The second issue I raised concerns the fact that running this code as part of our project will repeat the download each time. Since we would like to be good citizens and avoid unnecessary traffic on the web it would be nice if our code checked to see if we already have the data on disk and if it exists, then skip the download, if not then download it. To achieve this we need to introduce two new functions <code>if()</code> and <code>dir.exists()</code>. <code>dir.exists()</code> takes a path to a directory as an argument and returns the logical value, <code>TRUE</code>, if that directory exists, and <code>FALSE</code> if it does not. <code>if()</code> evaluates logical statements and processes subsequent code based on the logical value it is passed as an argument. Let’s look at a toy example.</p>
<pre class="r"><code>num &lt;- 1
if(num == 1) { 
  cat(num, &quot;is 1&quot;) 
  } else {
  cat(num, &quot;is not 1&quot;)
  }</code></pre>
<pre><code>## 1 is 1</code></pre>
<p>I assigned <code>num</code> to the value <code>1</code> and created a logical evaluation <code>num ==</code> whose result is passed as the argument to <code>if()</code>. If the statement returns <code>TRUE</code> then the code withing the first set of curly braces <code>{...}</code> is run. If <code>num == 1</code> is false, like in the code below, the code withing the braces following the <code>else</code> will be run.</p>
<pre class="r"><code>num &lt;- 2
if(num == 1) { 
  cat(num, &quot;is 1&quot;) 
  } else {
  cat(num, &quot;is not 1&quot;)
  }</code></pre>
<pre><code>## 2 is not 1</code></pre>
<p>The function <code>if()</code> is one of various functions that are called <strong>control statements</strong>. Theses functions provide a lot of power to make dynamic choices as code is run.</p>
<p>Before we get back to our key objective to avoid downloading resources that we already have on disk, let me introduce another strategy to making code more powerful and ultimately more efficient and as well as more legible –the <strong>custom function</strong>. Custom functions are functions that the user writes to create a set of procedures that can be run in similar contexts. I’ve created a custom function named <code>eval_num()</code> below.</p>
<pre class="r"><code>eval_num &lt;- function(num) {
  if(num == 1) { 
  cat(num, &quot;is 1&quot;) 
  } else {
  cat(num, &quot;is not 1&quot;)
  }
}</code></pre>
<p>Let’s take a closer look at what’s going on here. The function <code>function()</code> creates a function in which the user decides what arguments are necessary for the code to perform its task. In this case the only necessary argument is the object to store a numeric value to be evaluated. I’ve called it <code>num</code> because it reflects the name of the object in our toy example, but there is nothing special about this name. It’s only important that the object names be consistently used. I’ve included our previous code (except for the hard-coded assignment of <code>num</code>) inside the curly braces and assigned the entire code chunk to <code>eval_num</code>.</p>
<p>We can now use the function <code>eval_num()</code> to perform the task of evaluating whether a value of <code>num</code> is or is not equal to <code>1</code>.</p>
<pre class="r"><code>eval_num(num = 1)</code></pre>
<pre><code>## 1 is 1</code></pre>
<pre class="r"><code>eval_num(num = 2)</code></pre>
<pre><code>## 2 is not 1</code></pre>
<pre class="r"><code>eval_num(num = 3)</code></pre>
<pre><code>## 3 is not 1</code></pre>
<p>I’ve put these coding strategies together with our previous code in a function I named <code>get_zip_data()</code>. There is a lot going on here. Take a look first and see if you can follow the logic involved given what you now know.</p>
<pre class="r"><code>get_zip_data &lt;- function(url, target_dir) {
  # Function: to download and decompress a .zip file to a target directory
  
  # Check to see if the data already exists
  if(!dir.exists(target_dir)) { # if data does not exist, download/ decompress
    cat(&quot;Creating target data directory \n&quot;) # print status message
    dir.create(path = target_dir, recursive = TRUE, showWarnings = FALSE) # create target data directory
    cat(&quot;Downloading data... \n&quot;) # print status message
    temp &lt;- tempfile() # create a temporary space for the file to be written to
    download.file(url = url, destfile = temp) # download the data to the temp file
    unzip(zipfile = temp, exdir = target_dir, junkpaths = TRUE) # decompress the temp file in the target directory
    cat(&quot;Data downloaded! \n&quot;) # print status message
  } else { # if data exists, don&#39;t download it again
    cat(&quot;Data already exists \n&quot;) # print status message
  }
}</code></pre>
<p>OK. You should have recognized the general steps in this function: the argument <code>url</code> and <code>target_dir</code> specify where to get the data and where to write the decompressed files, the <code>if()</code> statement evaluates whether the data already exists, if not (<code>!dir.exists(target_dir)</code>) then the data is downloaded and decompressed, if it does exist (<code>else</code>) then it is not downloaded.</p>
<div class="alert alert-note">
  <p>The prefixed <code>!</code> in the logical expression <code>dir.exists(target_dir)</code> returns the opposite logical value. This is needed in this case so when the target directory exists, the expression will return <code>FALSE</code>, not <code>TRUE</code>, and therefore not proceed in downloading the resource.</p>

</div>

<p>There are a couple key tweaks I’ve added that provide some additional functionality. For one I’ve included the function <code>dir.create()</code> to create the target directory where the data will be written. I’ve also added an additional argument to the <code>unzip()</code> function, <code>junkpaths = TRUE</code>. Together these additions allow the user to create an arbitrary directory path where the files, and only the files, will be extracted to on our disk. This will discard the containing directory of the <code>.zip</code> file which can be helpful when we want to add multiple <code>.zip</code> files to the same target directory.</p>
<p>A practical scenario where this applies is when we want to download data from a corpus that is contained in multiple <code>.zip</code> files but still maintain these files in a single primary data directory. Take for example the <a href="http://www.linguistics.ucsb.edu/research/santa-barbara-corpus">Santa Barbara Corpus</a>. This corpus resource includes a series of interviews in which there is one <code>.zip</code> file, <code>SBCorpus.zip</code> which contains the <a href="http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/SBCorpus.zip">transcribed interviews</a> and another <code>.zip</code> file, <code>metadata.zip</code> which organizes the <a href="http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/metadata.zip">meta-data</a> associated with each speaker. Applying our initial strategy to download and decompress the data will lead to the following directory structure:</p>
<pre><code>data
├── derived
└── original
    ├── SBCorpus
    │   ├── TRN
    │   └── __MACOSX
    │       └── TRN
    └── metadata
        └── __MACOSX

8 directories</code></pre>
<p>By applying our new custom function <code>get_zip_data()</code> to the transcriptions and then the meta-data we can better organize the data.</p>
<pre class="r"><code># Download corpus transcriptions
get_zip_data(url = &quot;http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/SBCorpus.zip&quot;, target_dir = &quot;data/original/sbc/transcriptions/&quot;)

# Download corpus meta-data
get_zip_data(url = &quot;http://www.linguistics.ucsb.edu/sites/secure.lsit.ucsb.edu.ling.d7/files/sitefiles/research/SBC/metadata.zip&quot;, target_dir = &quot;data/original/sbc/meta-data/&quot;)</code></pre>
<p>Now our <code>data/</code> directory is better organized; both the transcriptions and the meta-data are housed under <code>data/original/sbc/</code>.</p>
<pre><code>data
├── derived
└── original
    └── sbc
        ├── meta-data
        └── transcriptions

5 directories</code></pre>
<p>If we add data from other sources we can keep them logical separate and allow our data collection to scale without creating unnecessary complexity. Let’s add the Switchboard Corpus sample using our <code>get_zip_data()</code> function to see this in action.</p>
<pre class="r"><code># Download corpus
get_zip_data(url = &quot;https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/switchboard.zip&quot;, target_dir = &quot;data/original/scs/&quot;)</code></pre>
<p>Our corpora our housed in their own directories and the files are clearly associated.</p>
<pre><code>data
├── derived
└── original
    ├── sbc
    │   ├── meta-data
    │   └── transcriptions
    └── scs

6 directories</code></pre>
<p>At this point we have what we need to continue to the next step in our data analysis project. But before we go, we should do some housekeeping to document and organize this process to make our work reproducible. We will take advantage of the <code>project-template</code> directory structure, seen below.</p>
<pre><code>.
├── README.md
├── _pipeline.R
├── code
│   ├── acquire_data.R
│   ├── analyze_data.R
│   ├── curate_data.R
│   ├── generate_reports.R
│   └── transform_data.R
├── data
│   ├── derived
│   └── original
├── figures
├── functions
├── log
├── recipes-acquire-data.Rproj
└── report
    ├── article.Rmd
    ├── bibliography.bib
    ├── slides.Rmd
    └── web.Rmd

8 directories, 13 files</code></pre>
<p>First it is good practice to separate custom functions from our processing scripts. We can create a file in our <code>functions/</code> directory named <code>acquire_functions.R</code> and add our custom function <code>get_zip_data()</code> there. We then use the <code>source()</code> function to read that function into our current script to make it available to use as needed. It is good practice to source your functions in the SETUP section of your script.</p>
<pre class="r"><code># Load custom functions for this project
source(file = &quot;functions/acquire_functions.R&quot;)</code></pre>
<p>Second it is advisable to log the structure of the data in plain text files. You can create a directory tree (as those seen in this post) with the bash command <code>tree</code> on the command line. R provides a function <code>system()</code> which will interface the command line. Adding the following code to the LOG section of your <code>acquire_data.R</code> R script will generate the directory structure for each of the corpora that we have downloaded in this post in the files <code>data_original_sbc.log</code> and <code>data_original_scs.log</code>.</p>
<pre class="r"><code># Log the directory structure of the Santa Barbara Corpus
system(command = &quot;tree data/original/sbc &gt;&gt; log/data_original_sbc.log&quot;)
# Log the directory structure of the Switchboard Corpus sample
system(command = &quot;tree data/original/scs &gt;&gt; log/data_original_scs.log&quot;)</code></pre>
<p>Our project directory structure now looks like this:</p>
<pre><code>.
├── README.md
├── _pipeline.R
├── code
│   ├── acquire_data.R
│   ├── analyze_data.R
│   ├── curate_data.R
│   ├── generate_reports.R
│   └── transform_data.R
├── data
│   ├── derived
│   └── original
├── figures
├── functions
│   └── acquire_functions.R
├── log
│   ├── data_original_sbc.log
│   └── data_original_scs.log
├── recipes-acquire-data.Rproj
└── report
    ├── article.Rmd
    ├── bibliography.bib
    ├── slides.Rmd
    └── web.Rmd

8 directories, 15 files</code></pre>
</div>
<div id="round-up" class="section level2">
<h2>Round up</h2>
<p>In this post we’ve covered how to access, download, and organize data contained in .zip files; the most common format for language data found on repositories and individual sites. This included an introduction to a few key R programming concepts and strategies including using functions, writing custom functions, and controlling program flow with control statements. Our approach was to gather data while also keeping in mind the reproducibility of the code. To this end I introduced programming strategies for avoiding unnecessary web traffic (downloads), scalable directory creation, and data documentation.</p>
<p>In the next post in this three part mini-series I will cover acquiring data from web services such as Project Gutenberg, Twitter, and Facebook through R packages. Using package interfaces will require additional knowledge of R objects. I will discuss vector types and data frames and show how to manipulate these objects in practical situations like filtering data and writing data to disk in plain-text files.</p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Remember base R packages are installed by default with R and are loaded and accessible by default in each R session.<a href="#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/reproducible-research/">reproducible research</a>
  
  <a class="badge badge-light" href="/tags/repositories/">repositories</a>
  
  <a class="badge badge-light" href="/tags/data/">data</a>
  
  <a class="badge badge-light" href="/tags/custom-functions/">custom functions</a>
  
  <a class="badge badge-light" href="/tags/control-statements/">control statements</a>
  
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/2017/10/04/data-for-language-research-types-and-sources/">Data for language research -types and sources</a></li>
        
        <li><a href="/2017/09/15/introduction-to-statistical-thinking/">Introduction to statistical thinking</a></li>
        
        <li><a href="/2017/08/31/project-management-for-scalable-data-analysis/">Project management for scalable data analysis</a></li>
        
      </ul>
    </div>
    

    

    
<section id="comments">
  <div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "francojc" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>



  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    Jerid Francom &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        CommonHTML: { linebreaks: { automatic: true } },
        tex2jax: { inlineMath: [ ['$', '$'], ['\\(','\\)'] ], displayMath: [ ['$$','$$'], ['\\[', '\\]'] ], processEscapes: false },
        TeX: { noUndefined: { attributes: { mathcolor: 'red', mathbackground: '#FFEEEE', mathsize: '90%' } } },
        messageStyle: 'none'
      });
    </script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/r.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/bash.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/css.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/markdown.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/shell.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/sql.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/tex.min.js"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    
      <script async defer src="//maps.googleapis.com/maps/api/js?key=AIzaSyCp-PTX7EwVGvo1lOhmK8PHZgakQLoz_RA"></script>
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/gmaps.js/0.4.25/gmaps.min.js" integrity="sha256-7vjlAeb8OaTrCXZkCNun9djzuB2owUsaO72kXaFDBJs=" crossorigin="anonymous"></script>
      
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "Search Results",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    <script src="/js/search.js"></script>
    

    
    

  </body>
</html>

